{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from hyperparams import Hyperparams as hp\n",
    "from layers import *\n",
    "from networks_v2 import *\n",
    "import tensorflow as tf\n",
    "from utils_v2 import *\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "import nvgpu\n",
    "import nvsmi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvsmi.get_gpus()\n",
    "nvsmi.get_available_gpus()\n",
    "nvsmi.get_gpu_processes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "with open('data/sorted_with_len_2000','rb') as f:\n",
    "    sorted_with_len_2000 = pickle.load(f)\n",
    "with open('data/sorted_with_len_4000','rb') as f:\n",
    "    sorted_with_len_4000 = pickle.load(f)\n",
    "with open('data/sorted_with_len_6000','rb') as f:\n",
    "    sorted_with_len_6000 = pickle.load(f)\n",
    "with open('data/sorted_with_len_8000','rb') as f:\n",
    "    sorted_with_len_8000 = pickle.load(f)\n",
    "with open('data/sorted_with_len_10000','rb') as f:\n",
    "    sorted_with_len_10000 = pickle.load(f)\n",
    "with open('data/sorted_with_len_12000','rb') as f:\n",
    "    sorted_with_len_12000 = pickle.load(f)\n",
    "with open('data/sorted_with_len_13099','rb') as f:\n",
    "    sorted_with_len_13099 = pickle.load(f)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "sorted_with_len = sorted_with_len_2000+sorted_with_len_4000+sorted_with_len_6000+sorted_with_len_8000+sorted_with_len_10000+sorted_with_len_12000+sorted_with_len_13099\n",
    "\n",
    "\n",
    "# start_time = time.time()\n",
    "text2mel_data = [(sent[0],sent[1]) for sent in sorted_with_len]\n",
    "all_dataset = tf.data.Dataset.from_generator(lambda : text2mel_data,\n",
    "                                            output_types = (tf.int32, tf.float32))\n",
    "pad_batch = all_dataset.padded_batch(16, padded_shapes=((None,),(None,hp.n_mels)))\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "textenc = TEXTENC()\n",
    "audioenc = AUDIOENC()\n",
    "audiodec = AUDIODEC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(text2mel_data)//16\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,\n",
    "    beta_1=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1),optimizer=optimizer,\n",
    "                                 textenc = textenc,\n",
    "                                 audioenc = audioenc,\n",
    "                                 audiodec = audiodec)\n",
    "manager = tf.train.CheckpointManager(ckpt, './training_checkpoints', max_to_keep=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train_step_signature = [\n",
    "#     tf.TensorSpec(shape=(None, ), dtype=tf.int32),\n",
    "#     tf.TensorSpec(shape=(None, hp.n_mels), dtype=tf.float32),\n",
    "# ]\n",
    "\n",
    "@tf.function\n",
    "def train_step(L,mels,prev_max_attentions):   \n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        K,V = textenc(L)\n",
    "        Q = audioenc(S)\n",
    "        R, alignments, max_attentions = Attention(Q, K, V,hp,\n",
    "                                                 mononotic_attention=False,\n",
    "                                                 prev_max_attentions=prev_max_attentions)\n",
    "        Y_logits, Y = audiodec(R)\n",
    "\n",
    "\n",
    "        loss_mels = tf.reduce_mean(tf.abs(Y - mels))\n",
    "\n",
    "        # mel binary divergence loss\n",
    "        loss_bd1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= Y_logits, labels= mels))\n",
    "\n",
    "        # guided_attention loss\n",
    "        A = tf.pad(alignments, [(0, 0), (0, hp.max_N), (0, hp.max_T)], mode=\"CONSTANT\", constant_values=-1.)[:, :hp.max_N, :hp.max_T]\n",
    "        attention_masks = tf.dtypes.cast(tf.not_equal(A, -1),tf.float32)\n",
    "        loss_att = tf.reduce_sum(tf.abs(A * gts) * attention_masks)\n",
    "        mask_sum = tf.reduce_sum(attention_masks)\n",
    "        loss_att /= mask_sum\n",
    "\n",
    "        # total loss\n",
    "        loss = loss_mels + loss_bd1 + loss_att\n",
    "\n",
    "\n",
    "    variables = textenc.trainable_variables + audioenc.trainable_variables + audiodec.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    gradients = [(tf.clip_by_value(grad, -1.0, 1.0))\n",
    "                                  for grad in gradients]\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    loss += loss\n",
    "    return loss, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing from scratch.\n",
      "Epoch 1 Batch 0 Loss 2.0513\n",
      "Saved checkpoint for epoch 0: ./training_checkpoints\\ckpt-1\n",
      "Epoch 1 Batch 0 Loss 2.0513\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 10 Loss 1.7387\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 20 Loss 1.2746\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 30 Loss 1.3535\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 40 Loss 1.5874\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 12 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 50 Loss 1.4821\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 60 Loss 1.2459\n",
      "WARNING:tensorflow:11 out of the last 12 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 70 Loss 1.4653\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 80 Loss 1.2740\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 90 Loss 1.3498\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 100 Loss 1.2249\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 110 Loss 1.2508\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 120 Loss 1.1698\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x000002067A2384C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Time taken for 1 epoch 595.9995634555817 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.5105\n",
      "Saved checkpoint for epoch 1: ./training_checkpoints\\ckpt-2\n",
      "Epoch 2 Batch 0 Loss 1.5105\n",
      "Epoch 2 Batch 10 Loss 1.2522\n",
      "Epoch 2 Batch 20 Loss 1.2013\n",
      "Epoch 2 Batch 30 Loss 1.3267\n",
      "Epoch 2 Batch 40 Loss 1.3109\n",
      "Epoch 2 Batch 50 Loss 1.1689\n",
      "Epoch 2 Batch 60 Loss 1.1594\n",
      "Epoch 2 Batch 70 Loss 1.3714\n",
      "Epoch 2 Batch 80 Loss 1.2125\n",
      "Epoch 2 Batch 90 Loss 1.3257\n",
      "Epoch 2 Batch 100 Loss 1.2090\n",
      "Epoch 2 Batch 110 Loss 1.2440\n",
      "Epoch 2 Batch 120 Loss 1.1561\n",
      "Time taken for 1 epoch 22.61944031715393 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.5472\n",
      "Saved checkpoint for epoch 2: ./training_checkpoints\\ckpt-3\n",
      "Epoch 3 Batch 0 Loss 1.5472\n",
      "Epoch 3 Batch 10 Loss 1.2937\n",
      "Epoch 3 Batch 20 Loss 1.1819\n",
      "Epoch 3 Batch 30 Loss 1.3081\n",
      "Epoch 3 Batch 40 Loss 1.3178\n",
      "Epoch 3 Batch 50 Loss 1.1725\n",
      "Epoch 3 Batch 60 Loss 1.1641\n",
      "Epoch 3 Batch 70 Loss 1.3720\n",
      "Epoch 3 Batch 80 Loss 1.1902\n",
      "Epoch 3 Batch 90 Loss 1.2693\n",
      "Epoch 3 Batch 100 Loss 1.1441\n",
      "Epoch 3 Batch 110 Loss 1.1879\n",
      "Epoch 3 Batch 120 Loss 1.1065\n",
      "Time taken for 1 epoch 22.88404369354248 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.0887\n",
      "Saved checkpoint for epoch 3: ./training_checkpoints\\ckpt-4\n",
      "Epoch 4 Batch 0 Loss 1.0887\n",
      "Epoch 4 Batch 10 Loss 1.1818\n",
      "Epoch 4 Batch 20 Loss 1.0339\n",
      "Epoch 4 Batch 30 Loss 1.2071\n",
      "Epoch 4 Batch 40 Loss 1.3709\n",
      "Epoch 4 Batch 50 Loss 1.1148\n",
      "Epoch 4 Batch 60 Loss 1.0564\n",
      "Epoch 4 Batch 70 Loss 1.3297\n",
      "Epoch 4 Batch 80 Loss 1.1091\n",
      "Epoch 4 Batch 90 Loss 1.2197\n",
      "Epoch 4 Batch 100 Loss 1.0832\n",
      "Epoch 4 Batch 110 Loss 1.1541\n",
      "Epoch 4 Batch 120 Loss 1.1088\n",
      "Time taken for 1 epoch 23.080510139465332 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.0690\n",
      "Saved checkpoint for epoch 4: ./training_checkpoints\\ckpt-5\n",
      "Epoch 5 Batch 0 Loss 1.0690\n",
      "Epoch 5 Batch 10 Loss 1.1007\n",
      "Epoch 5 Batch 20 Loss 1.0049\n",
      "Epoch 5 Batch 30 Loss 1.1755\n",
      "Epoch 5 Batch 40 Loss 1.2763\n",
      "Epoch 5 Batch 50 Loss 1.1277\n",
      "Epoch 5 Batch 60 Loss 1.3543\n",
      "Epoch 5 Batch 70 Loss 1.3876\n",
      "Epoch 5 Batch 80 Loss 1.1754\n",
      "Epoch 5 Batch 90 Loss 1.2618\n",
      "Epoch 5 Batch 100 Loss 1.0872\n",
      "Epoch 5 Batch 110 Loss 1.1587\n",
      "Epoch 5 Batch 120 Loss 1.1183\n",
      "Time taken for 1 epoch 23.498323678970337 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.9895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint for epoch 5: ./training_checkpoints\\ckpt-6\n",
      "Epoch 6 Batch 0 Loss 0.9895\n",
      "Epoch 6 Batch 10 Loss 1.0998\n",
      "Epoch 6 Batch 20 Loss 1.0050\n",
      "Epoch 6 Batch 30 Loss 1.1685\n",
      "Epoch 6 Batch 40 Loss 1.2278\n",
      "Epoch 6 Batch 50 Loss 1.0643\n",
      "Epoch 6 Batch 60 Loss 1.0156\n",
      "Epoch 6 Batch 70 Loss 1.2943\n",
      "Epoch 6 Batch 80 Loss 1.0936\n",
      "Epoch 6 Batch 90 Loss 1.2017\n",
      "Epoch 6 Batch 100 Loss 1.0670\n",
      "Epoch 6 Batch 110 Loss 1.1419\n",
      "Epoch 6 Batch 120 Loss 1.1144\n",
      "Time taken for 1 epoch 24.37058734893799 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.0996\n",
      "Saved checkpoint for epoch 6: ./training_checkpoints\\ckpt-7\n",
      "Epoch 7 Batch 0 Loss 1.0996\n",
      "Epoch 7 Batch 10 Loss 1.0956\n",
      "Epoch 7 Batch 20 Loss 1.0019\n",
      "Epoch 7 Batch 30 Loss 1.1680\n",
      "Epoch 7 Batch 40 Loss 1.2179\n",
      "Epoch 7 Batch 50 Loss 1.0549\n",
      "Epoch 7 Batch 60 Loss 1.0051\n",
      "Epoch 7 Batch 70 Loss 1.3056\n",
      "Epoch 7 Batch 80 Loss 1.0974\n",
      "Epoch 7 Batch 90 Loss 1.1998\n",
      "Epoch 7 Batch 100 Loss 1.0688\n",
      "Epoch 7 Batch 110 Loss 1.1403\n",
      "Epoch 7 Batch 120 Loss 1.0986\n",
      "Time taken for 1 epoch 24.341386556625366 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.0551\n",
      "Saved checkpoint for epoch 7: ./training_checkpoints\\ckpt-8\n",
      "Epoch 8 Batch 0 Loss 1.0551\n",
      "Epoch 8 Batch 10 Loss 1.0984\n",
      "Epoch 8 Batch 20 Loss 0.9965\n",
      "Epoch 8 Batch 30 Loss 1.1662\n",
      "Epoch 8 Batch 40 Loss 1.2122\n",
      "Epoch 8 Batch 50 Loss 1.0414\n",
      "Epoch 8 Batch 60 Loss 0.9924\n",
      "Epoch 8 Batch 70 Loss 1.2776\n",
      "Epoch 8 Batch 80 Loss 1.0790\n",
      "Epoch 8 Batch 90 Loss 1.1867\n",
      "Epoch 8 Batch 100 Loss 1.0568\n",
      "Epoch 8 Batch 110 Loss 1.1332\n",
      "Epoch 8 Batch 120 Loss 1.0583\n",
      "Time taken for 1 epoch 24.51788902282715 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.0243\n",
      "Saved checkpoint for epoch 8: ./training_checkpoints\\ckpt-9\n",
      "Epoch 9 Batch 0 Loss 1.0243\n",
      "Epoch 9 Batch 10 Loss 1.0952\n",
      "Epoch 9 Batch 20 Loss 0.9998\n",
      "Epoch 9 Batch 30 Loss 1.1534\n",
      "Epoch 9 Batch 40 Loss 1.2010\n",
      "Epoch 9 Batch 50 Loss 1.0405\n",
      "Epoch 9 Batch 60 Loss 0.9923\n",
      "Epoch 9 Batch 70 Loss 1.2715\n",
      "Epoch 9 Batch 80 Loss 1.0747\n",
      "Epoch 9 Batch 90 Loss 1.1843\n",
      "Epoch 9 Batch 100 Loss 1.0542\n",
      "Epoch 9 Batch 110 Loss 1.1290\n",
      "Epoch 9 Batch 120 Loss 1.0431\n",
      "Time taken for 1 epoch 24.04644012451172 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.0268\n",
      "Saved checkpoint for epoch 9: ./training_checkpoints\\ckpt-10\n",
      "Epoch 10 Batch 0 Loss 1.0268\n",
      "Epoch 10 Batch 10 Loss 1.0799\n",
      "Epoch 10 Batch 20 Loss 0.9857\n",
      "Epoch 10 Batch 30 Loss 1.1441\n",
      "Epoch 10 Batch 40 Loss 1.1962\n",
      "Epoch 10 Batch 50 Loss 1.0363\n",
      "Epoch 10 Batch 60 Loss 0.9864\n",
      "Epoch 10 Batch 70 Loss 1.2670\n",
      "Epoch 10 Batch 80 Loss 1.0703\n",
      "Epoch 10 Batch 90 Loss 1.1790\n",
      "Epoch 10 Batch 100 Loss 1.0504\n",
      "Epoch 10 Batch 110 Loss 1.1260\n",
      "Epoch 10 Batch 120 Loss 1.0321\n",
      "Time taken for 1 epoch 24.37705659866333 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.9756\n",
      "Saved checkpoint for epoch 10: ./training_checkpoints\\ckpt-11\n",
      "Epoch 11 Batch 0 Loss 0.9756\n",
      "Epoch 11 Batch 10 Loss 1.0785\n",
      "Epoch 11 Batch 20 Loss 0.9824\n",
      "Epoch 11 Batch 30 Loss 1.1426\n",
      "Epoch 11 Batch 40 Loss 1.1911\n",
      "Epoch 11 Batch 50 Loss 1.0337\n",
      "Epoch 11 Batch 60 Loss 0.9851\n",
      "Epoch 11 Batch 70 Loss 1.2638\n",
      "Epoch 11 Batch 80 Loss 1.0690\n",
      "Epoch 11 Batch 90 Loss 1.1763\n",
      "Epoch 11 Batch 100 Loss 1.0478\n",
      "Epoch 11 Batch 110 Loss 1.1244\n",
      "Epoch 11 Batch 120 Loss 1.0364\n",
      "Time taken for 1 epoch 24.498868465423584 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.9602\n",
      "Saved checkpoint for epoch 11: ./training_checkpoints\\ckpt-12\n",
      "Epoch 12 Batch 0 Loss 0.9602\n",
      "Epoch 12 Batch 10 Loss 1.0803\n",
      "Epoch 12 Batch 20 Loss 0.9779\n",
      "Epoch 12 Batch 30 Loss 1.1385\n",
      "Epoch 12 Batch 40 Loss 1.1893\n",
      "Epoch 12 Batch 50 Loss 1.0339\n",
      "Epoch 12 Batch 60 Loss 0.9805\n",
      "Epoch 12 Batch 70 Loss 1.2606\n",
      "Epoch 12 Batch 80 Loss 1.0657\n",
      "Epoch 12 Batch 90 Loss 1.1738\n",
      "Epoch 12 Batch 100 Loss 1.0455\n",
      "Epoch 12 Batch 110 Loss 1.1218\n",
      "Epoch 12 Batch 120 Loss 1.0290\n",
      "Time taken for 1 epoch 25.13842463493347 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.9583\n",
      "Saved checkpoint for epoch 12: ./training_checkpoints\\ckpt-13\n",
      "Epoch 13 Batch 0 Loss 0.9583\n",
      "Epoch 13 Batch 10 Loss 1.0783\n",
      "Epoch 13 Batch 20 Loss 0.9766\n",
      "Epoch 13 Batch 30 Loss 1.1338\n",
      "Epoch 13 Batch 40 Loss 1.1877\n",
      "Epoch 13 Batch 50 Loss 1.0293\n",
      "Epoch 13 Batch 60 Loss 0.9798\n",
      "Epoch 13 Batch 70 Loss 1.2587\n",
      "Epoch 13 Batch 80 Loss 1.0648\n",
      "Epoch 13 Batch 90 Loss 1.1720\n",
      "Epoch 13 Batch 100 Loss 1.0439\n",
      "Epoch 13 Batch 110 Loss 1.1221\n",
      "Epoch 13 Batch 120 Loss 1.0310\n",
      "Time taken for 1 epoch 23.69443941116333 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.9385\n",
      "Saved checkpoint for epoch 13: ./training_checkpoints\\ckpt-14\n",
      "Epoch 14 Batch 0 Loss 0.9385\n",
      "Epoch 14 Batch 10 Loss 1.0783\n",
      "Epoch 14 Batch 20 Loss 0.9723\n",
      "Epoch 14 Batch 30 Loss 1.1304\n",
      "Epoch 14 Batch 40 Loss 1.1909\n",
      "Epoch 14 Batch 50 Loss 1.0280\n",
      "Epoch 14 Batch 60 Loss 0.9773\n",
      "Epoch 14 Batch 70 Loss 1.2580\n",
      "Epoch 14 Batch 80 Loss 1.0618\n",
      "Epoch 14 Batch 90 Loss 1.1707\n",
      "Epoch 14 Batch 100 Loss 1.0422\n",
      "Epoch 14 Batch 110 Loss 1.1209\n",
      "Epoch 14 Batch 120 Loss 1.0298\n",
      "Time taken for 1 epoch 24.725785732269287 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.9372\n",
      "Saved checkpoint for epoch 14: ./training_checkpoints\\ckpt-15\n",
      "Epoch 15 Batch 0 Loss 0.9372\n",
      "Epoch 15 Batch 10 Loss 1.0817\n",
      "Epoch 15 Batch 20 Loss 0.9704\n",
      "Epoch 15 Batch 30 Loss 1.1282\n",
      "Epoch 15 Batch 40 Loss 1.1857\n",
      "Epoch 15 Batch 50 Loss 1.0251\n",
      "Epoch 15 Batch 60 Loss 0.9756\n",
      "Epoch 15 Batch 70 Loss 1.2554\n",
      "Epoch 15 Batch 80 Loss 1.0612\n",
      "Epoch 15 Batch 90 Loss 1.1693\n",
      "Epoch 15 Batch 100 Loss 1.0405\n",
      "Epoch 15 Batch 110 Loss 1.1191\n",
      "Epoch 15 Batch 120 Loss 1.0254\n",
      "Time taken for 1 epoch 24.59260869026184 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.9211\n",
      "Saved checkpoint for epoch 15: ./training_checkpoints\\ckpt-16\n",
      "Epoch 16 Batch 0 Loss 0.9211\n",
      "Epoch 16 Batch 10 Loss 1.0813\n",
      "Epoch 16 Batch 20 Loss 0.9700\n",
      "Epoch 16 Batch 30 Loss 1.1260\n",
      "Epoch 16 Batch 40 Loss 1.1842\n",
      "Epoch 16 Batch 50 Loss 1.0235\n",
      "Epoch 16 Batch 60 Loss 0.9747\n",
      "Epoch 16 Batch 70 Loss 1.2545\n",
      "Epoch 16 Batch 80 Loss 1.0602\n",
      "Epoch 16 Batch 90 Loss 1.1674\n",
      "Epoch 16 Batch 100 Loss 1.0389\n",
      "Epoch 16 Batch 110 Loss 1.1187\n",
      "Epoch 16 Batch 120 Loss 1.0263\n",
      "Time taken for 1 epoch 25.60476303100586 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.9101\n",
      "Saved checkpoint for epoch 16: ./training_checkpoints\\ckpt-17\n",
      "Epoch 17 Batch 0 Loss 0.9101\n",
      "Epoch 17 Batch 10 Loss 1.0766\n",
      "Epoch 17 Batch 20 Loss 0.9657\n",
      "Epoch 17 Batch 30 Loss 1.1216\n",
      "Epoch 17 Batch 40 Loss 1.1924\n",
      "Epoch 17 Batch 50 Loss 1.0245\n",
      "Epoch 17 Batch 60 Loss 0.9777\n",
      "Epoch 17 Batch 70 Loss 1.2569\n",
      "Epoch 17 Batch 80 Loss 1.0600\n",
      "Epoch 17 Batch 90 Loss 1.1673\n",
      "Epoch 17 Batch 100 Loss 1.0391\n",
      "Epoch 17 Batch 110 Loss 1.1178\n",
      "Epoch 17 Batch 120 Loss 1.0257\n",
      "Time taken for 1 epoch 24.816312551498413 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.9105\n",
      "Saved checkpoint for epoch 17: ./training_checkpoints\\ckpt-18\n",
      "Epoch 18 Batch 0 Loss 0.9105\n",
      "Epoch 18 Batch 10 Loss 1.0732\n",
      "Epoch 18 Batch 20 Loss 0.9658\n",
      "Epoch 18 Batch 30 Loss 1.1211\n",
      "Epoch 18 Batch 40 Loss 1.2018\n",
      "Epoch 18 Batch 50 Loss 1.0231\n",
      "Epoch 18 Batch 60 Loss 0.9775\n",
      "Epoch 18 Batch 70 Loss 1.2544\n",
      "Epoch 18 Batch 80 Loss 1.0582\n",
      "Epoch 18 Batch 90 Loss 1.1669\n",
      "Epoch 18 Batch 100 Loss 1.0379\n",
      "Epoch 18 Batch 110 Loss 1.1166\n",
      "Epoch 18 Batch 120 Loss 1.0338\n",
      "Time taken for 1 epoch 24.968249082565308 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.9257\n",
      "Saved checkpoint for epoch 18: ./training_checkpoints\\ckpt-19\n",
      "Epoch 19 Batch 0 Loss 0.9257\n",
      "Epoch 19 Batch 10 Loss 1.0727\n",
      "Epoch 19 Batch 20 Loss 0.9657\n",
      "Epoch 19 Batch 30 Loss 1.1198\n",
      "Epoch 19 Batch 40 Loss 1.1832\n",
      "Epoch 19 Batch 50 Loss 1.0224\n",
      "Epoch 19 Batch 60 Loss 0.9743\n",
      "Epoch 19 Batch 70 Loss 1.2538\n",
      "Epoch 19 Batch 80 Loss 1.0567\n",
      "Epoch 19 Batch 90 Loss 1.1662\n",
      "Epoch 19 Batch 100 Loss 1.0377\n",
      "Epoch 19 Batch 110 Loss 1.1147\n",
      "Epoch 19 Batch 120 Loss 1.0207\n",
      "Time taken for 1 epoch 24.983188152313232 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.9108\n",
      "Saved checkpoint for epoch 19: ./training_checkpoints\\ckpt-20\n",
      "Epoch 20 Batch 0 Loss 0.9108\n",
      "Epoch 20 Batch 10 Loss 1.0718\n",
      "Epoch 20 Batch 20 Loss 0.9640\n",
      "Epoch 20 Batch 30 Loss 1.1169\n",
      "Epoch 20 Batch 40 Loss 1.1779\n",
      "Epoch 20 Batch 50 Loss 1.0180\n",
      "Epoch 20 Batch 60 Loss 0.9730\n",
      "Epoch 20 Batch 70 Loss 1.2502\n",
      "Epoch 20 Batch 80 Loss 1.0549\n",
      "Epoch 20 Batch 90 Loss 1.1646\n",
      "Epoch 20 Batch 100 Loss 1.0368\n",
      "Epoch 20 Batch 110 Loss 1.1136\n",
      "Epoch 20 Batch 120 Loss 1.0146\n",
      "Time taken for 1 epoch 25.068623065948486 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.8983\n",
      "Saved checkpoint for epoch 20: ./training_checkpoints\\ckpt-21\n",
      "Epoch 21 Batch 0 Loss 0.8983\n",
      "Epoch 21 Batch 10 Loss 1.0687\n",
      "Epoch 21 Batch 20 Loss 0.9678\n",
      "Epoch 21 Batch 30 Loss 1.1191\n",
      "Epoch 21 Batch 40 Loss 1.1779\n",
      "Epoch 21 Batch 50 Loss 1.0178\n",
      "Epoch 21 Batch 60 Loss 0.9702\n",
      "Epoch 21 Batch 70 Loss 1.2474\n",
      "Epoch 21 Batch 80 Loss 1.0545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 90 Loss 1.1628\n",
      "Epoch 21 Batch 100 Loss 1.0355\n",
      "Epoch 21 Batch 110 Loss 1.1106\n",
      "Epoch 21 Batch 120 Loss 1.0110\n",
      "Time taken for 1 epoch 25.044119358062744 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.8980\n",
      "Saved checkpoint for epoch 21: ./training_checkpoints\\ckpt-22\n",
      "Epoch 22 Batch 0 Loss 0.8980\n",
      "Epoch 22 Batch 10 Loss 1.0723\n",
      "Epoch 22 Batch 20 Loss 0.9616\n",
      "Epoch 22 Batch 30 Loss 1.1151\n",
      "Epoch 22 Batch 40 Loss 1.1775\n",
      "Epoch 22 Batch 50 Loss 1.0159\n",
      "Epoch 22 Batch 60 Loss 0.9699\n",
      "Epoch 22 Batch 70 Loss 1.2462\n",
      "Epoch 22 Batch 80 Loss 1.0563\n",
      "Epoch 22 Batch 90 Loss 1.1623\n",
      "Epoch 22 Batch 100 Loss 1.0335\n",
      "Epoch 22 Batch 110 Loss 1.1086\n",
      "Epoch 22 Batch 120 Loss 1.0123\n",
      "Time taken for 1 epoch 25.412463426589966 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.9001\n",
      "Saved checkpoint for epoch 22: ./training_checkpoints\\ckpt-23\n",
      "Epoch 23 Batch 0 Loss 0.9001\n",
      "Epoch 23 Batch 10 Loss 1.0694\n",
      "Epoch 23 Batch 20 Loss 0.9602\n",
      "Epoch 23 Batch 30 Loss 1.1134\n",
      "Epoch 23 Batch 40 Loss 1.1741\n",
      "Epoch 23 Batch 50 Loss 1.0141\n",
      "Epoch 23 Batch 60 Loss 0.9707\n",
      "Epoch 23 Batch 70 Loss 1.2463\n",
      "Epoch 23 Batch 80 Loss 1.0538\n",
      "Epoch 23 Batch 90 Loss 1.1606\n",
      "Epoch 23 Batch 100 Loss 1.0313\n",
      "Epoch 23 Batch 110 Loss 1.1077\n",
      "Epoch 23 Batch 120 Loss 1.0151\n",
      "Time taken for 1 epoch 24.680418014526367 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.8815\n",
      "Saved checkpoint for epoch 23: ./training_checkpoints\\ckpt-24\n",
      "Epoch 24 Batch 0 Loss 0.8815\n",
      "Epoch 24 Batch 10 Loss 1.0649\n",
      "Epoch 24 Batch 20 Loss 0.9564\n",
      "Epoch 24 Batch 30 Loss 1.1071\n",
      "Epoch 24 Batch 40 Loss 1.1695\n",
      "Epoch 24 Batch 50 Loss 1.0119\n",
      "Epoch 24 Batch 60 Loss 0.9688\n",
      "Epoch 24 Batch 70 Loss 1.2453\n",
      "Epoch 24 Batch 80 Loss 1.0507\n",
      "Epoch 24 Batch 90 Loss 1.1590\n",
      "Epoch 24 Batch 100 Loss 1.0303\n",
      "Epoch 24 Batch 110 Loss 1.1030\n",
      "Epoch 24 Batch 120 Loss 1.0128\n",
      "Time taken for 1 epoch 24.631380319595337 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.8819\n",
      "Saved checkpoint for epoch 24: ./training_checkpoints\\ckpt-25\n",
      "Epoch 25 Batch 0 Loss 0.8819\n",
      "Epoch 25 Batch 10 Loss 1.0587\n",
      "Epoch 25 Batch 20 Loss 0.9519\n",
      "Epoch 25 Batch 30 Loss 1.1081\n",
      "Epoch 25 Batch 40 Loss 1.1769\n",
      "Epoch 25 Batch 50 Loss 1.0099\n",
      "Epoch 25 Batch 60 Loss 0.9668\n",
      "Epoch 25 Batch 70 Loss 1.2444\n",
      "Epoch 25 Batch 80 Loss 1.0506\n",
      "Epoch 25 Batch 90 Loss 1.1572\n",
      "Epoch 25 Batch 100 Loss 1.0310\n",
      "Epoch 25 Batch 110 Loss 1.1004\n",
      "Epoch 25 Batch 120 Loss 1.0086\n",
      "Time taken for 1 epoch 25.177916526794434 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.8906\n",
      "Saved checkpoint for epoch 25: ./training_checkpoints\\ckpt-26\n",
      "Epoch 26 Batch 0 Loss 0.8906\n",
      "Epoch 26 Batch 10 Loss 1.0591\n",
      "Epoch 26 Batch 20 Loss 0.9553\n",
      "Epoch 26 Batch 30 Loss 1.1032\n",
      "Epoch 26 Batch 40 Loss 1.1766\n",
      "Epoch 26 Batch 50 Loss 1.0122\n",
      "Epoch 26 Batch 60 Loss 0.9686\n",
      "Epoch 26 Batch 70 Loss 1.2452\n",
      "Epoch 26 Batch 80 Loss 1.0506\n",
      "Epoch 26 Batch 90 Loss 1.1566\n",
      "Epoch 26 Batch 100 Loss 1.0303\n",
      "Epoch 26 Batch 110 Loss 1.0982\n",
      "Epoch 26 Batch 120 Loss 1.0081\n",
      "Time taken for 1 epoch 26.10232377052307 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.8899\n",
      "Saved checkpoint for epoch 26: ./training_checkpoints\\ckpt-27\n",
      "Epoch 27 Batch 0 Loss 0.8899\n",
      "Epoch 27 Batch 10 Loss 1.0576\n",
      "Epoch 27 Batch 20 Loss 0.9528\n",
      "Epoch 27 Batch 30 Loss 1.1066\n",
      "Epoch 27 Batch 40 Loss 1.1672\n",
      "Epoch 27 Batch 50 Loss 1.0118\n",
      "Epoch 27 Batch 60 Loss 0.9644\n",
      "Epoch 27 Batch 70 Loss 1.2412\n",
      "Epoch 27 Batch 80 Loss 1.0479\n",
      "Epoch 27 Batch 90 Loss 1.1548\n",
      "Epoch 27 Batch 100 Loss 1.0300\n",
      "Epoch 27 Batch 110 Loss 1.0984\n",
      "Epoch 27 Batch 120 Loss 1.0149\n",
      "Time taken for 1 epoch 25.38993263244629 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.8567\n",
      "Saved checkpoint for epoch 27: ./training_checkpoints\\ckpt-28\n",
      "Epoch 28 Batch 0 Loss 0.8567\n",
      "Epoch 28 Batch 10 Loss 1.0521\n",
      "Epoch 28 Batch 20 Loss 0.9513\n",
      "Epoch 28 Batch 30 Loss 1.1033\n",
      "Epoch 28 Batch 40 Loss 1.1683\n",
      "Epoch 28 Batch 50 Loss 1.0115\n",
      "Epoch 28 Batch 60 Loss 0.9675\n",
      "Epoch 28 Batch 70 Loss 1.2398\n",
      "Epoch 28 Batch 80 Loss 1.0474\n",
      "Epoch 28 Batch 90 Loss 1.1493\n",
      "Epoch 28 Batch 100 Loss 1.0260\n",
      "Epoch 28 Batch 110 Loss 1.0977\n",
      "Epoch 28 Batch 120 Loss 1.0055\n",
      "Time taken for 1 epoch 23.516433000564575 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.8996\n",
      "Saved checkpoint for epoch 28: ./training_checkpoints\\ckpt-29\n",
      "Epoch 29 Batch 0 Loss 0.8996\n",
      "Epoch 29 Batch 10 Loss 1.0599\n",
      "Epoch 29 Batch 20 Loss 0.9503\n",
      "Epoch 29 Batch 30 Loss 1.1005\n",
      "Epoch 29 Batch 40 Loss 1.1735\n",
      "Epoch 29 Batch 50 Loss 1.0154\n",
      "Epoch 29 Batch 60 Loss 0.9684\n",
      "Epoch 29 Batch 70 Loss 1.2440\n",
      "Epoch 29 Batch 80 Loss 1.0488\n",
      "Epoch 29 Batch 90 Loss 1.1509\n",
      "Epoch 29 Batch 100 Loss 1.0234\n",
      "Epoch 29 Batch 110 Loss 1.0944\n",
      "Epoch 29 Batch 120 Loss 1.0225\n",
      "Time taken for 1 epoch 23.986389636993408 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.9056\n",
      "Saved checkpoint for epoch 29: ./training_checkpoints\\ckpt-30\n",
      "Epoch 30 Batch 0 Loss 0.9056\n",
      "Epoch 30 Batch 10 Loss 1.0666\n",
      "Epoch 30 Batch 20 Loss 0.9526\n",
      "Epoch 30 Batch 30 Loss 1.1004\n",
      "Epoch 30 Batch 40 Loss 1.1880\n",
      "Epoch 30 Batch 50 Loss 1.0140\n",
      "Epoch 30 Batch 60 Loss 0.9707\n",
      "Epoch 30 Batch 70 Loss 1.2427\n",
      "Epoch 30 Batch 80 Loss 1.0471\n",
      "Epoch 30 Batch 90 Loss 1.1488\n",
      "Epoch 30 Batch 100 Loss 1.0207\n",
      "Epoch 30 Batch 110 Loss 1.0881\n",
      "Epoch 30 Batch 120 Loss 1.0339\n",
      "Time taken for 1 epoch 24.225252866744995 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.9186\n",
      "Saved checkpoint for epoch 30: ./training_checkpoints\\ckpt-31\n",
      "Epoch 31 Batch 0 Loss 0.9186\n",
      "Epoch 31 Batch 10 Loss 1.0629\n",
      "Epoch 31 Batch 20 Loss 0.9510\n",
      "Epoch 31 Batch 30 Loss 1.0989\n",
      "Epoch 31 Batch 40 Loss 1.1675\n",
      "Epoch 31 Batch 50 Loss 1.0038\n",
      "Epoch 31 Batch 60 Loss 0.9652\n",
      "Epoch 31 Batch 70 Loss 1.2375\n",
      "Epoch 31 Batch 80 Loss 1.0443\n",
      "Epoch 31 Batch 90 Loss 1.1441\n",
      "Epoch 31 Batch 100 Loss 1.0168\n",
      "Epoch 31 Batch 110 Loss 1.0882\n",
      "Epoch 31 Batch 120 Loss 1.0127\n",
      "Time taken for 1 epoch 25.27249813079834 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.9952\n",
      "Saved checkpoint for epoch 31: ./training_checkpoints\\ckpt-32\n",
      "Epoch 32 Batch 0 Loss 0.9952\n",
      "Epoch 32 Batch 10 Loss 1.0702\n",
      "Epoch 32 Batch 20 Loss 0.9560\n",
      "Epoch 32 Batch 30 Loss 1.0987\n",
      "Epoch 32 Batch 40 Loss 1.1747\n",
      "Epoch 32 Batch 50 Loss 1.0124\n",
      "Epoch 32 Batch 60 Loss 0.9716\n",
      "Epoch 32 Batch 70 Loss 1.2423\n",
      "Epoch 32 Batch 80 Loss 1.0487\n",
      "Epoch 32 Batch 90 Loss 1.1465\n",
      "Epoch 32 Batch 100 Loss 1.0162\n",
      "Epoch 32 Batch 110 Loss 1.0929\n",
      "Epoch 32 Batch 120 Loss 1.0850\n",
      "Time taken for 1 epoch 23.80585551261902 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.8823\n",
      "Saved checkpoint for epoch 32: ./training_checkpoints\\ckpt-33\n",
      "Epoch 33 Batch 0 Loss 0.8823\n",
      "Epoch 33 Batch 10 Loss 1.0559\n",
      "Epoch 33 Batch 20 Loss 0.9520\n",
      "Epoch 33 Batch 30 Loss 1.0970\n",
      "Epoch 33 Batch 40 Loss 1.1610\n",
      "Epoch 33 Batch 50 Loss 1.0024\n",
      "Epoch 33 Batch 60 Loss 0.9791\n",
      "Epoch 33 Batch 70 Loss 1.2376\n",
      "Epoch 33 Batch 80 Loss 1.0451\n",
      "Epoch 33 Batch 90 Loss 1.1447\n",
      "Epoch 33 Batch 100 Loss 1.0112\n",
      "Epoch 33 Batch 110 Loss 1.0806\n",
      "Epoch 33 Batch 120 Loss 1.0205\n",
      "Time taken for 1 epoch 22.988041877746582 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.9022\n",
      "Saved checkpoint for epoch 33: ./training_checkpoints\\ckpt-34\n",
      "Epoch 34 Batch 0 Loss 0.9022\n",
      "Epoch 34 Batch 10 Loss 1.0621\n",
      "Epoch 34 Batch 20 Loss 0.9509\n",
      "Epoch 34 Batch 30 Loss 1.0889\n",
      "Epoch 34 Batch 40 Loss 1.1575\n",
      "Epoch 34 Batch 50 Loss 1.0019\n",
      "Epoch 34 Batch 60 Loss 0.9659\n",
      "Epoch 34 Batch 70 Loss 1.2311\n",
      "Epoch 34 Batch 80 Loss 1.0414\n",
      "Epoch 34 Batch 90 Loss 1.1379\n",
      "Epoch 34 Batch 100 Loss 1.0129\n",
      "Epoch 34 Batch 110 Loss 1.0766\n",
      "Epoch 34 Batch 120 Loss 0.9959\n",
      "Time taken for 1 epoch 23.539543867111206 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.8793\n",
      "Saved checkpoint for epoch 34: ./training_checkpoints\\ckpt-35\n",
      "Epoch 35 Batch 0 Loss 0.8793\n",
      "Epoch 35 Batch 10 Loss 1.0488\n",
      "Epoch 35 Batch 20 Loss 0.9482\n",
      "Epoch 35 Batch 30 Loss 1.0864\n",
      "Epoch 35 Batch 40 Loss 1.1615\n",
      "Epoch 35 Batch 50 Loss 1.0026\n",
      "Epoch 35 Batch 60 Loss 0.9633\n",
      "Epoch 35 Batch 70 Loss 1.2255\n",
      "Epoch 35 Batch 80 Loss 1.0367\n",
      "Epoch 35 Batch 90 Loss 1.1356\n",
      "Epoch 35 Batch 100 Loss 1.0070\n",
      "Epoch 35 Batch 110 Loss 1.0764\n",
      "Epoch 35 Batch 120 Loss 1.0123\n",
      "Time taken for 1 epoch 24.959771156311035 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.9606\n",
      "Saved checkpoint for epoch 35: ./training_checkpoints\\ckpt-36\n",
      "Epoch 36 Batch 0 Loss 0.9606\n",
      "Epoch 36 Batch 10 Loss 1.0639\n",
      "Epoch 36 Batch 20 Loss 0.9564\n",
      "Epoch 36 Batch 30 Loss 1.1037\n",
      "Epoch 36 Batch 40 Loss 1.1853\n",
      "Epoch 36 Batch 50 Loss 1.0084\n",
      "Epoch 36 Batch 60 Loss 0.9850\n",
      "Epoch 36 Batch 70 Loss 1.2453\n",
      "Epoch 36 Batch 80 Loss 1.0486\n",
      "Epoch 36 Batch 90 Loss 1.1473\n",
      "Epoch 36 Batch 100 Loss 1.0232\n",
      "Epoch 36 Batch 110 Loss 1.0875\n",
      "Epoch 36 Batch 120 Loss 1.0357\n",
      "Time taken for 1 epoch 23.204620599746704 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 1.1321\n",
      "Saved checkpoint for epoch 36: ./training_checkpoints\\ckpt-37\n",
      "Epoch 37 Batch 0 Loss 1.1321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 10 Loss 1.0858\n",
      "Epoch 37 Batch 20 Loss 0.9722\n",
      "Epoch 37 Batch 30 Loss 1.1198\n",
      "Epoch 37 Batch 40 Loss 1.2552\n",
      "Epoch 37 Batch 50 Loss 242468.5156\n",
      "Epoch 37 Batch 60 Loss 1.6921\n",
      "Epoch 37 Batch 70 Loss 1.5788\n",
      "Epoch 37 Batch 80 Loss 1.5555\n",
      "Epoch 37 Batch 90 Loss 1.5154\n",
      "Epoch 37 Batch 100 Loss 1.4990\n",
      "Epoch 37 Batch 110 Loss 1.4756\n",
      "Epoch 37 Batch 120 Loss 1.4649\n",
      "Time taken for 1 epoch 23.17484188079834 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 1.4403\n",
      "Saved checkpoint for epoch 37: ./training_checkpoints\\ckpt-38\n",
      "Epoch 38 Batch 0 Loss 1.4403\n",
      "Epoch 38 Batch 10 Loss 1.4477\n",
      "Epoch 38 Batch 20 Loss 1.4381\n",
      "Epoch 38 Batch 30 Loss 1.4441\n",
      "Epoch 38 Batch 40 Loss 1.4425\n",
      "Epoch 38 Batch 50 Loss 1.4208\n",
      "Epoch 38 Batch 60 Loss 1.4192\n",
      "Epoch 38 Batch 70 Loss 1.4794\n",
      "Epoch 38 Batch 80 Loss 1.3965\n",
      "Epoch 38 Batch 90 Loss 1.4412\n",
      "Epoch 38 Batch 100 Loss 1.4126\n",
      "Epoch 38 Batch 110 Loss 1.4188\n",
      "Epoch 38 Batch 120 Loss 1.3939\n",
      "Time taken for 1 epoch 23.020256519317627 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 1.3475\n",
      "Saved checkpoint for epoch 38: ./training_checkpoints\\ckpt-39\n",
      "Epoch 39 Batch 0 Loss 1.3475\n",
      "Epoch 39 Batch 10 Loss 1.4154\n",
      "Epoch 39 Batch 20 Loss 1.3964\n",
      "Epoch 39 Batch 30 Loss 1.4299\n",
      "Epoch 39 Batch 40 Loss 1.4397\n",
      "Epoch 39 Batch 50 Loss 1.3976\n",
      "Epoch 39 Batch 60 Loss 1.3957\n",
      "Epoch 39 Batch 70 Loss 1.4872\n",
      "Epoch 39 Batch 80 Loss 1.3931\n",
      "Epoch 39 Batch 90 Loss 1.4414\n",
      "Epoch 39 Batch 100 Loss 1.4107\n",
      "Epoch 39 Batch 110 Loss 1.4172\n",
      "Epoch 39 Batch 120 Loss 1.3924\n",
      "Time taken for 1 epoch 24.164315700531006 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 1.3454\n",
      "Saved checkpoint for epoch 39: ./training_checkpoints\\ckpt-40\n",
      "Epoch 40 Batch 0 Loss 1.3454\n",
      "Epoch 40 Batch 10 Loss 1.4147\n",
      "Epoch 40 Batch 20 Loss 1.3954\n",
      "Epoch 40 Batch 30 Loss 1.4296\n",
      "Epoch 40 Batch 40 Loss 1.4393\n",
      "Epoch 40 Batch 50 Loss 1.3969\n",
      "Epoch 40 Batch 60 Loss 1.3949\n",
      "Epoch 40 Batch 70 Loss 1.4876\n",
      "Epoch 40 Batch 80 Loss 1.3927\n",
      "Epoch 40 Batch 90 Loss 1.4415\n",
      "Epoch 40 Batch 100 Loss 1.4104\n",
      "Epoch 40 Batch 110 Loss 1.4170\n",
      "Epoch 40 Batch 120 Loss 1.3921\n",
      "Time taken for 1 epoch 24.19945526123047 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 1.3448\n",
      "Saved checkpoint for epoch 40: ./training_checkpoints\\ckpt-41\n",
      "Epoch 41 Batch 0 Loss 1.3448\n",
      "Epoch 41 Batch 10 Loss 1.4144\n",
      "Epoch 41 Batch 20 Loss 1.3952\n",
      "Epoch 41 Batch 30 Loss 1.4296\n",
      "Epoch 41 Batch 40 Loss 1.4393\n",
      "Epoch 41 Batch 50 Loss 1.3967\n",
      "Epoch 41 Batch 60 Loss 1.3946\n",
      "Epoch 41 Batch 70 Loss 1.4878\n",
      "Epoch 41 Batch 80 Loss 1.3925\n",
      "Epoch 41 Batch 90 Loss 1.4415\n",
      "Epoch 41 Batch 100 Loss 1.4103\n",
      "Epoch 41 Batch 110 Loss 1.4169\n",
      "Epoch 41 Batch 120 Loss 1.3920\n",
      "Time taken for 1 epoch 24.190765857696533 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 1.3447\n",
      "Saved checkpoint for epoch 41: ./training_checkpoints\\ckpt-42\n",
      "Epoch 42 Batch 0 Loss 1.3447\n",
      "Epoch 42 Batch 10 Loss 1.4144\n",
      "Epoch 42 Batch 20 Loss 1.3951\n",
      "Epoch 42 Batch 30 Loss 1.4296\n",
      "Epoch 42 Batch 40 Loss 1.4392\n",
      "Epoch 42 Batch 50 Loss 1.3966\n",
      "Epoch 42 Batch 60 Loss 1.3945\n",
      "Epoch 42 Batch 70 Loss 1.4879\n",
      "Epoch 42 Batch 80 Loss 1.3925\n",
      "Epoch 42 Batch 90 Loss 1.4416\n",
      "Epoch 42 Batch 100 Loss 1.4102\n",
      "Epoch 42 Batch 110 Loss 1.4169\n",
      "Epoch 42 Batch 120 Loss 1.3920\n",
      "Time taken for 1 epoch 22.593920469284058 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 1.3447\n",
      "Saved checkpoint for epoch 42: ./training_checkpoints\\ckpt-43\n",
      "Epoch 43 Batch 0 Loss 1.3447\n",
      "Epoch 43 Batch 10 Loss 1.4143\n",
      "Epoch 43 Batch 20 Loss 1.3951\n",
      "Epoch 43 Batch 30 Loss 1.4296\n",
      "Epoch 43 Batch 40 Loss 1.4392\n",
      "Epoch 43 Batch 50 Loss 1.3966\n",
      "Epoch 43 Batch 60 Loss 1.3945\n",
      "Epoch 43 Batch 70 Loss 1.4879\n",
      "Epoch 43 Batch 80 Loss 1.3925\n",
      "Epoch 43 Batch 90 Loss 1.4416\n",
      "Epoch 43 Batch 100 Loss 1.4102\n",
      "Epoch 43 Batch 110 Loss 1.4169\n",
      "Epoch 43 Batch 120 Loss 1.3919\n",
      "Time taken for 1 epoch 23.578967094421387 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 1.3447\n",
      "Saved checkpoint for epoch 43: ./training_checkpoints\\ckpt-44\n",
      "Epoch 44 Batch 0 Loss 1.3447\n",
      "Epoch 44 Batch 10 Loss 1.4143\n",
      "Epoch 44 Batch 20 Loss 1.3951\n",
      "Epoch 44 Batch 30 Loss 1.4296\n",
      "Epoch 44 Batch 40 Loss 1.4392\n",
      "Epoch 44 Batch 50 Loss 1.3965\n",
      "Epoch 44 Batch 60 Loss 1.3944\n",
      "Epoch 44 Batch 70 Loss 1.4880\n",
      "Epoch 44 Batch 80 Loss 1.3925\n",
      "Epoch 44 Batch 90 Loss 1.4416\n",
      "Epoch 44 Batch 100 Loss 1.4102\n",
      "Epoch 44 Batch 110 Loss 1.4169\n",
      "Epoch 44 Batch 120 Loss 1.3919\n",
      "Time taken for 1 epoch 23.11302876472473 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 1.3448\n",
      "Saved checkpoint for epoch 44: ./training_checkpoints\\ckpt-45\n",
      "Epoch 45 Batch 0 Loss 1.3448\n",
      "Epoch 45 Batch 10 Loss 1.4143\n",
      "Epoch 45 Batch 20 Loss 1.3951\n",
      "Epoch 45 Batch 30 Loss 1.4296\n",
      "Epoch 45 Batch 40 Loss 1.4392\n",
      "Epoch 45 Batch 50 Loss 1.3965\n",
      "Epoch 45 Batch 60 Loss 1.3944\n",
      "Epoch 45 Batch 70 Loss 1.4880\n",
      "Epoch 45 Batch 80 Loss 1.3924\n",
      "Epoch 45 Batch 90 Loss 1.4416\n",
      "Epoch 45 Batch 100 Loss 1.4102\n",
      "Epoch 45 Batch 110 Loss 1.4169\n",
      "Epoch 45 Batch 120 Loss 1.3919\n",
      "Time taken for 1 epoch 23.130000591278076 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 1.3448\n",
      "Saved checkpoint for epoch 45: ./training_checkpoints\\ckpt-46\n",
      "Epoch 46 Batch 0 Loss 1.3448\n",
      "Epoch 46 Batch 10 Loss 1.4143\n",
      "Epoch 46 Batch 20 Loss 1.3951\n",
      "Epoch 46 Batch 30 Loss 1.4296\n",
      "Epoch 46 Batch 40 Loss 1.4392\n",
      "Epoch 46 Batch 50 Loss 1.3965\n",
      "Epoch 46 Batch 60 Loss 1.3944\n",
      "Epoch 46 Batch 70 Loss 1.4880\n",
      "Epoch 46 Batch 80 Loss 1.3924\n",
      "Epoch 46 Batch 90 Loss 1.4416\n",
      "Epoch 46 Batch 100 Loss 1.4101\n",
      "Epoch 46 Batch 110 Loss 1.4169\n",
      "Epoch 46 Batch 120 Loss 1.3920\n",
      "Time taken for 1 epoch 23.569525718688965 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 1.3449\n",
      "Saved checkpoint for epoch 46: ./training_checkpoints\\ckpt-47\n",
      "Epoch 47 Batch 0 Loss 1.3449\n",
      "Epoch 47 Batch 10 Loss 1.4143\n",
      "Epoch 47 Batch 20 Loss 1.3951\n",
      "Epoch 47 Batch 30 Loss 1.4296\n",
      "Epoch 47 Batch 40 Loss 1.4392\n",
      "Epoch 47 Batch 50 Loss 1.3965\n",
      "Epoch 47 Batch 60 Loss 1.3944\n",
      "Epoch 47 Batch 70 Loss 1.4881\n",
      "Epoch 47 Batch 80 Loss 1.3924\n",
      "Epoch 47 Batch 90 Loss 1.4416\n",
      "Epoch 47 Batch 100 Loss 1.4101\n",
      "Epoch 47 Batch 110 Loss 1.4169\n",
      "Epoch 47 Batch 120 Loss 1.3920\n",
      "Time taken for 1 epoch 23.279804706573486 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 1.3449\n",
      "Saved checkpoint for epoch 47: ./training_checkpoints\\ckpt-48\n",
      "Epoch 48 Batch 0 Loss 1.3449\n",
      "Epoch 48 Batch 10 Loss 1.4143\n",
      "Epoch 48 Batch 20 Loss 1.3951\n",
      "Epoch 48 Batch 30 Loss 1.4296\n",
      "Epoch 48 Batch 40 Loss 1.4392\n",
      "Epoch 48 Batch 50 Loss 1.3965\n",
      "Epoch 48 Batch 60 Loss 1.3944\n",
      "Epoch 48 Batch 70 Loss 1.4881\n",
      "Epoch 48 Batch 80 Loss 1.3924\n",
      "Epoch 48 Batch 90 Loss 1.4416\n",
      "Epoch 48 Batch 100 Loss 1.4101\n",
      "Epoch 48 Batch 110 Loss 1.4169\n",
      "Epoch 48 Batch 120 Loss 1.3920\n",
      "Time taken for 1 epoch 23.114614486694336 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 1.3450\n",
      "Saved checkpoint for epoch 48: ./training_checkpoints\\ckpt-49\n",
      "Epoch 49 Batch 0 Loss 1.3450\n",
      "Epoch 49 Batch 10 Loss 1.4143\n",
      "Epoch 49 Batch 20 Loss 1.3951\n",
      "Epoch 49 Batch 30 Loss 1.4296\n",
      "Epoch 49 Batch 40 Loss 1.4391\n",
      "Epoch 49 Batch 50 Loss 1.3965\n",
      "Epoch 49 Batch 60 Loss 1.3944\n",
      "Epoch 49 Batch 70 Loss 1.4882\n",
      "Epoch 49 Batch 80 Loss 1.3924\n",
      "Epoch 49 Batch 90 Loss 1.4416\n",
      "Epoch 49 Batch 100 Loss 1.4101\n",
      "Epoch 49 Batch 110 Loss 1.4169\n",
      "Epoch 49 Batch 120 Loss 1.3920\n",
      "Time taken for 1 epoch 23.228770971298218 sec\n",
      "\n",
      "Epoch 50 Batch 0 Loss 1.3450\n",
      "Saved checkpoint for epoch 49: ./training_checkpoints\\ckpt-50\n",
      "Epoch 50 Batch 0 Loss 1.3450\n",
      "Epoch 50 Batch 10 Loss 1.4143\n",
      "Epoch 50 Batch 20 Loss 1.3951\n",
      "Epoch 50 Batch 30 Loss 1.4296\n",
      "Epoch 50 Batch 40 Loss 1.4391\n",
      "Epoch 50 Batch 50 Loss 1.3965\n",
      "Epoch 50 Batch 60 Loss 1.3943\n",
      "Epoch 50 Batch 70 Loss 1.4882\n",
      "Epoch 50 Batch 80 Loss 1.3924\n",
      "Epoch 50 Batch 90 Loss 1.4416\n",
      "Epoch 50 Batch 100 Loss 1.4101\n",
      "Epoch 50 Batch 110 Loss 1.4169\n",
      "Epoch 50 Batch 120 Loss 1.3920\n",
      "Time taken for 1 epoch 23.124054431915283 sec\n",
      "\n",
      "Epoch 51 Batch 0 Loss 1.3450\n",
      "Saved checkpoint for epoch 50: ./training_checkpoints\\ckpt-51\n",
      "Epoch 51 Batch 0 Loss 1.3450\n",
      "Epoch 51 Batch 10 Loss 1.4143\n",
      "Epoch 51 Batch 20 Loss 1.3952\n",
      "Epoch 51 Batch 30 Loss 1.4296\n",
      "Epoch 51 Batch 40 Loss 1.4391\n",
      "Epoch 51 Batch 50 Loss 1.3965\n",
      "Epoch 51 Batch 60 Loss 1.3943\n",
      "Epoch 51 Batch 70 Loss 1.4883\n",
      "Epoch 51 Batch 80 Loss 1.3924\n",
      "Epoch 51 Batch 90 Loss 1.4416\n",
      "Epoch 51 Batch 100 Loss 1.4101\n",
      "Epoch 51 Batch 110 Loss 1.4169\n",
      "Epoch 51 Batch 120 Loss 1.3920\n",
      "Time taken for 1 epoch 23.28011178970337 sec\n",
      "\n",
      "Epoch 52 Batch 0 Loss 1.3451\n",
      "Saved checkpoint for epoch 51: ./training_checkpoints\\ckpt-52\n",
      "Epoch 52 Batch 0 Loss 1.3451\n",
      "Epoch 52 Batch 10 Loss 1.4143\n",
      "Epoch 52 Batch 20 Loss 1.3952\n",
      "Epoch 52 Batch 30 Loss 1.4296\n",
      "Epoch 52 Batch 40 Loss 1.4391\n",
      "Epoch 52 Batch 50 Loss 1.3965\n",
      "Epoch 52 Batch 60 Loss 1.3943\n",
      "Epoch 52 Batch 70 Loss 1.4883\n",
      "Epoch 52 Batch 80 Loss 1.3924\n",
      "Epoch 52 Batch 90 Loss 1.4416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 100 Loss 1.4101\n",
      "Epoch 52 Batch 110 Loss 1.4169\n",
      "Epoch 52 Batch 120 Loss 1.3920\n",
      "Time taken for 1 epoch 24.061362981796265 sec\n",
      "\n",
      "Epoch 53 Batch 0 Loss 1.3451\n",
      "Saved checkpoint for epoch 52: ./training_checkpoints\\ckpt-53\n",
      "Epoch 53 Batch 0 Loss 1.3451\n",
      "Epoch 53 Batch 10 Loss 1.4143\n",
      "Epoch 53 Batch 20 Loss 1.3952\n",
      "Epoch 53 Batch 30 Loss 1.4296\n",
      "Epoch 53 Batch 40 Loss 1.4391\n",
      "Epoch 53 Batch 50 Loss 1.3965\n",
      "Epoch 53 Batch 60 Loss 1.3943\n",
      "Epoch 53 Batch 70 Loss 1.4883\n",
      "Epoch 53 Batch 80 Loss 1.3924\n",
      "Epoch 53 Batch 90 Loss 1.4416\n",
      "Epoch 53 Batch 100 Loss 1.4101\n",
      "Epoch 53 Batch 110 Loss 1.4169\n",
      "Epoch 53 Batch 120 Loss 1.3920\n",
      "Time taken for 1 epoch 23.67700481414795 sec\n",
      "\n",
      "Epoch 54 Batch 0 Loss 1.3452\n",
      "Saved checkpoint for epoch 53: ./training_checkpoints\\ckpt-54\n",
      "Epoch 54 Batch 0 Loss 1.3452\n",
      "Epoch 54 Batch 10 Loss 1.4143\n",
      "Epoch 54 Batch 20 Loss 1.3952\n",
      "Epoch 54 Batch 30 Loss 1.4296\n",
      "Epoch 54 Batch 40 Loss 1.4391\n",
      "Epoch 54 Batch 50 Loss 1.3965\n",
      "Epoch 54 Batch 60 Loss 1.3943\n",
      "Epoch 54 Batch 70 Loss 1.4884\n",
      "Epoch 54 Batch 80 Loss 1.3924\n",
      "Epoch 54 Batch 90 Loss 1.4416\n",
      "Epoch 54 Batch 100 Loss 1.4101\n",
      "Epoch 54 Batch 110 Loss 1.4169\n",
      "Epoch 54 Batch 120 Loss 1.3921\n",
      "Time taken for 1 epoch 24.549293994903564 sec\n",
      "\n",
      "Epoch 55 Batch 0 Loss 1.3452\n",
      "Saved checkpoint for epoch 54: ./training_checkpoints\\ckpt-55\n",
      "Epoch 55 Batch 0 Loss 1.3452\n",
      "Epoch 55 Batch 10 Loss 1.4143\n",
      "Epoch 55 Batch 20 Loss 1.3952\n",
      "Epoch 55 Batch 30 Loss 1.4296\n",
      "Epoch 55 Batch 40 Loss 1.4391\n",
      "Epoch 55 Batch 50 Loss 1.3965\n",
      "Epoch 55 Batch 60 Loss 1.3943\n",
      "Epoch 55 Batch 70 Loss 1.4884\n",
      "Epoch 55 Batch 80 Loss 1.3924\n",
      "Epoch 55 Batch 90 Loss 1.4416\n",
      "Epoch 55 Batch 100 Loss 1.4101\n",
      "Epoch 55 Batch 110 Loss 1.4169\n",
      "Epoch 55 Batch 120 Loss 1.3921\n",
      "Time taken for 1 epoch 24.167439460754395 sec\n",
      "\n",
      "Epoch 56 Batch 0 Loss 1.3453\n",
      "Saved checkpoint for epoch 55: ./training_checkpoints\\ckpt-56\n",
      "Epoch 56 Batch 0 Loss 1.3453\n",
      "Epoch 56 Batch 10 Loss 1.4143\n",
      "Epoch 56 Batch 20 Loss 1.3952\n",
      "Epoch 56 Batch 30 Loss 1.4296\n",
      "Epoch 56 Batch 40 Loss 1.4391\n",
      "Epoch 56 Batch 50 Loss 1.3965\n",
      "Epoch 56 Batch 60 Loss 1.3943\n",
      "Epoch 56 Batch 70 Loss 1.4884\n",
      "Epoch 56 Batch 80 Loss 1.3924\n",
      "Epoch 56 Batch 90 Loss 1.4416\n",
      "Epoch 56 Batch 100 Loss 1.4101\n",
      "Epoch 56 Batch 110 Loss 1.4169\n",
      "Epoch 56 Batch 120 Loss 1.3921\n",
      "Time taken for 1 epoch 23.081716060638428 sec\n",
      "\n",
      "Epoch 57 Batch 0 Loss 1.3453\n",
      "Saved checkpoint for epoch 56: ./training_checkpoints\\ckpt-57\n",
      "Epoch 57 Batch 0 Loss 1.3453\n",
      "Epoch 57 Batch 10 Loss 1.4143\n",
      "Epoch 57 Batch 20 Loss 1.3952\n",
      "Epoch 57 Batch 30 Loss 1.4296\n",
      "Epoch 57 Batch 40 Loss 1.4391\n",
      "Epoch 57 Batch 50 Loss 1.3965\n",
      "Epoch 57 Batch 60 Loss 1.3943\n",
      "Epoch 57 Batch 70 Loss 1.4885\n",
      "Epoch 57 Batch 80 Loss 1.3924\n",
      "Epoch 57 Batch 90 Loss 1.4417\n",
      "Epoch 57 Batch 100 Loss 1.4101\n",
      "Epoch 57 Batch 110 Loss 1.4169\n",
      "Epoch 57 Batch 120 Loss 1.3921\n",
      "Time taken for 1 epoch 23.354349374771118 sec\n",
      "\n",
      "Epoch 58 Batch 0 Loss 1.3454\n",
      "Saved checkpoint for epoch 57: ./training_checkpoints\\ckpt-58\n",
      "Epoch 58 Batch 0 Loss 1.3454\n",
      "Epoch 58 Batch 10 Loss 1.4144\n",
      "Epoch 58 Batch 20 Loss 1.3952\n",
      "Epoch 58 Batch 30 Loss 1.4296\n",
      "Epoch 58 Batch 40 Loss 1.4392\n",
      "Epoch 58 Batch 50 Loss 1.3965\n",
      "Epoch 58 Batch 60 Loss 1.3943\n",
      "Epoch 58 Batch 70 Loss 1.4885\n",
      "Epoch 58 Batch 80 Loss 1.3924\n",
      "Epoch 58 Batch 90 Loss 1.4417\n",
      "Epoch 58 Batch 100 Loss 1.4101\n",
      "Epoch 58 Batch 110 Loss 1.4169\n",
      "Epoch 58 Batch 120 Loss 1.3921\n",
      "Time taken for 1 epoch 23.941847324371338 sec\n",
      "\n",
      "Epoch 59 Batch 0 Loss 1.3454\n",
      "Saved checkpoint for epoch 58: ./training_checkpoints\\ckpt-59\n",
      "Epoch 59 Batch 0 Loss 1.3454\n",
      "Epoch 59 Batch 10 Loss 1.4144\n",
      "Epoch 59 Batch 20 Loss 1.3952\n",
      "Epoch 59 Batch 30 Loss 1.4296\n",
      "Epoch 59 Batch 40 Loss 1.4392\n",
      "Epoch 59 Batch 50 Loss 1.3964\n",
      "Epoch 59 Batch 60 Loss 1.3943\n",
      "Epoch 59 Batch 70 Loss 1.4885\n",
      "Epoch 59 Batch 80 Loss 1.3923\n",
      "Epoch 59 Batch 90 Loss 1.4417\n",
      "Epoch 59 Batch 100 Loss 1.4101\n",
      "Epoch 59 Batch 110 Loss 1.4169\n",
      "Epoch 59 Batch 120 Loss 1.3921\n",
      "Time taken for 1 epoch 24.370919227600098 sec\n",
      "\n",
      "Epoch 60 Batch 0 Loss 1.3454\n",
      "Saved checkpoint for epoch 59: ./training_checkpoints\\ckpt-60\n",
      "Epoch 60 Batch 0 Loss 1.3454\n",
      "Epoch 60 Batch 10 Loss 1.4144\n",
      "Epoch 60 Batch 20 Loss 1.3952\n",
      "Epoch 60 Batch 30 Loss 1.4296\n",
      "Epoch 60 Batch 40 Loss 1.4392\n",
      "Epoch 60 Batch 50 Loss 1.3964\n",
      "Epoch 60 Batch 60 Loss 1.3943\n",
      "Epoch 60 Batch 70 Loss 1.4886\n",
      "Epoch 60 Batch 80 Loss 1.3923\n",
      "Epoch 60 Batch 90 Loss 1.4417\n",
      "Epoch 60 Batch 100 Loss 1.4101\n",
      "Epoch 60 Batch 110 Loss 1.4169\n",
      "Epoch 60 Batch 120 Loss 1.3921\n",
      "Time taken for 1 epoch 23.15889596939087 sec\n",
      "\n",
      "Epoch 61 Batch 0 Loss 1.3455\n",
      "Saved checkpoint for epoch 60: ./training_checkpoints\\ckpt-61\n",
      "Epoch 61 Batch 0 Loss 1.3455\n",
      "Epoch 61 Batch 10 Loss 1.4144\n",
      "Epoch 61 Batch 20 Loss 1.3952\n",
      "Epoch 61 Batch 30 Loss 1.4296\n",
      "Epoch 61 Batch 40 Loss 1.4392\n",
      "Epoch 61 Batch 50 Loss 1.3964\n",
      "Epoch 61 Batch 60 Loss 1.3942\n",
      "Epoch 61 Batch 70 Loss 1.4886\n",
      "Epoch 61 Batch 80 Loss 1.3923\n",
      "Epoch 61 Batch 90 Loss 1.4417\n",
      "Epoch 61 Batch 100 Loss 1.4101\n",
      "Epoch 61 Batch 110 Loss 1.4169\n",
      "Epoch 61 Batch 120 Loss 1.3922\n",
      "Time taken for 1 epoch 22.94316339492798 sec\n",
      "\n",
      "Epoch 62 Batch 0 Loss 1.3455\n",
      "Saved checkpoint for epoch 61: ./training_checkpoints\\ckpt-62\n",
      "Epoch 62 Batch 0 Loss 1.3455\n",
      "Epoch 62 Batch 10 Loss 1.4144\n",
      "Epoch 62 Batch 20 Loss 1.3953\n",
      "Epoch 62 Batch 30 Loss 1.4296\n",
      "Epoch 62 Batch 40 Loss 1.4392\n",
      "Epoch 62 Batch 50 Loss 1.3964\n",
      "Epoch 62 Batch 60 Loss 1.3942\n",
      "Epoch 62 Batch 70 Loss 1.4886\n",
      "Epoch 62 Batch 80 Loss 1.3923\n",
      "Epoch 62 Batch 90 Loss 1.4417\n",
      "Epoch 62 Batch 100 Loss 1.4101\n",
      "Epoch 62 Batch 110 Loss 1.4169\n",
      "Epoch 62 Batch 120 Loss 1.3922\n",
      "Time taken for 1 epoch 22.974735021591187 sec\n",
      "\n",
      "Epoch 63 Batch 0 Loss 1.3456\n",
      "Saved checkpoint for epoch 62: ./training_checkpoints\\ckpt-63\n",
      "Epoch 63 Batch 0 Loss 1.3456\n",
      "Epoch 63 Batch 10 Loss 1.4144\n",
      "Epoch 63 Batch 20 Loss 1.3953\n",
      "Epoch 63 Batch 30 Loss 1.4296\n",
      "Epoch 63 Batch 40 Loss 1.4392\n",
      "Epoch 63 Batch 50 Loss 1.3964\n",
      "Epoch 63 Batch 60 Loss 1.3942\n",
      "Epoch 63 Batch 70 Loss 1.4887\n",
      "Epoch 63 Batch 80 Loss 1.3923\n",
      "Epoch 63 Batch 90 Loss 1.4417\n",
      "Epoch 63 Batch 100 Loss 1.4101\n",
      "Epoch 63 Batch 110 Loss 1.4169\n",
      "Epoch 63 Batch 120 Loss 1.3922\n",
      "Time taken for 1 epoch 23.65131711959839 sec\n",
      "\n",
      "Epoch 64 Batch 0 Loss 1.3456\n",
      "Saved checkpoint for epoch 63: ./training_checkpoints\\ckpt-64\n",
      "Epoch 64 Batch 0 Loss 1.3456\n",
      "Epoch 64 Batch 10 Loss 1.4144\n",
      "Epoch 64 Batch 20 Loss 1.3953\n",
      "Epoch 64 Batch 30 Loss 1.4296\n",
      "Epoch 64 Batch 40 Loss 1.4392\n",
      "Epoch 64 Batch 50 Loss 1.3964\n",
      "Epoch 64 Batch 60 Loss 1.3942\n",
      "Epoch 64 Batch 70 Loss 1.4887\n",
      "Epoch 64 Batch 80 Loss 1.3923\n",
      "Epoch 64 Batch 90 Loss 1.4417\n",
      "Epoch 64 Batch 100 Loss 1.4101\n",
      "Epoch 64 Batch 110 Loss 1.4169\n",
      "Epoch 64 Batch 120 Loss 1.3922\n",
      "Time taken for 1 epoch 23.243420839309692 sec\n",
      "\n",
      "Epoch 65 Batch 0 Loss 1.3457\n",
      "Saved checkpoint for epoch 64: ./training_checkpoints\\ckpt-65\n",
      "Epoch 65 Batch 0 Loss 1.3457\n",
      "Epoch 65 Batch 10 Loss 1.4144\n",
      "Epoch 65 Batch 20 Loss 1.3953\n",
      "Epoch 65 Batch 30 Loss 1.4296\n",
      "Epoch 65 Batch 40 Loss 1.4392\n",
      "Epoch 65 Batch 50 Loss 1.3964\n",
      "Epoch 65 Batch 60 Loss 1.3942\n",
      "Epoch 65 Batch 70 Loss 1.4888\n",
      "Epoch 65 Batch 80 Loss 1.3923\n",
      "Epoch 65 Batch 90 Loss 1.4417\n",
      "Epoch 65 Batch 100 Loss 1.4101\n",
      "Epoch 65 Batch 110 Loss 1.4169\n",
      "Epoch 65 Batch 120 Loss 1.3922\n",
      "Time taken for 1 epoch 23.0715913772583 sec\n",
      "\n",
      "Epoch 66 Batch 0 Loss 1.3457\n",
      "Saved checkpoint for epoch 65: ./training_checkpoints\\ckpt-66\n",
      "Epoch 66 Batch 0 Loss 1.3457\n",
      "Epoch 66 Batch 10 Loss 1.4144\n",
      "Epoch 66 Batch 20 Loss 1.3953\n",
      "Epoch 66 Batch 30 Loss 1.4296\n",
      "Epoch 66 Batch 40 Loss 1.4392\n",
      "Epoch 66 Batch 50 Loss 1.3964\n",
      "Epoch 66 Batch 60 Loss 1.3942\n",
      "Epoch 66 Batch 70 Loss 1.4888\n",
      "Epoch 66 Batch 80 Loss 1.3923\n",
      "Epoch 66 Batch 90 Loss 1.4417\n",
      "Epoch 66 Batch 100 Loss 1.4101\n",
      "Epoch 66 Batch 110 Loss 1.4169\n",
      "Epoch 66 Batch 120 Loss 1.3922\n",
      "Time taken for 1 epoch 22.919204473495483 sec\n",
      "\n",
      "Epoch 67 Batch 0 Loss 1.3458\n",
      "Saved checkpoint for epoch 66: ./training_checkpoints\\ckpt-67\n",
      "Epoch 67 Batch 0 Loss 1.3458\n",
      "Epoch 67 Batch 10 Loss 1.4144\n",
      "Epoch 67 Batch 20 Loss 1.3953\n",
      "Epoch 67 Batch 30 Loss 1.4296\n",
      "Epoch 67 Batch 40 Loss 1.4392\n",
      "Epoch 67 Batch 50 Loss 1.3964\n",
      "Epoch 67 Batch 60 Loss 1.3942\n",
      "Epoch 67 Batch 70 Loss 1.4888\n",
      "Epoch 67 Batch 80 Loss 1.3923\n",
      "Epoch 67 Batch 90 Loss 1.4417\n",
      "Epoch 67 Batch 100 Loss 1.4101\n",
      "Epoch 67 Batch 110 Loss 1.4169\n",
      "Epoch 67 Batch 120 Loss 1.3923\n",
      "Time taken for 1 epoch 23.402125597000122 sec\n",
      "\n",
      "Epoch 68 Batch 0 Loss 1.3458\n",
      "Saved checkpoint for epoch 67: ./training_checkpoints\\ckpt-68\n",
      "Epoch 68 Batch 0 Loss 1.3458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 10 Loss 1.4144\n",
      "Epoch 68 Batch 20 Loss 1.3953\n",
      "Epoch 68 Batch 30 Loss 1.4296\n",
      "Epoch 68 Batch 40 Loss 1.4392\n",
      "Epoch 68 Batch 50 Loss 1.3964\n",
      "Epoch 68 Batch 60 Loss 1.3942\n",
      "Epoch 68 Batch 70 Loss 1.4889\n",
      "Epoch 68 Batch 80 Loss 1.3923\n",
      "Epoch 68 Batch 90 Loss 1.4417\n",
      "Epoch 68 Batch 100 Loss 1.4102\n",
      "Epoch 68 Batch 110 Loss 1.4169\n",
      "Epoch 68 Batch 120 Loss 1.3923\n",
      "Time taken for 1 epoch 22.797633409500122 sec\n",
      "\n",
      "Epoch 69 Batch 0 Loss 1.3459\n",
      "Saved checkpoint for epoch 68: ./training_checkpoints\\ckpt-69\n",
      "Epoch 69 Batch 0 Loss 1.3459\n",
      "Epoch 69 Batch 10 Loss 1.4144\n",
      "Epoch 69 Batch 20 Loss 1.3953\n",
      "Epoch 69 Batch 30 Loss 1.4296\n",
      "Epoch 69 Batch 40 Loss 1.4392\n",
      "Epoch 69 Batch 50 Loss 1.3964\n",
      "Epoch 69 Batch 60 Loss 1.3942\n",
      "Epoch 69 Batch 70 Loss 1.4889\n",
      "Epoch 69 Batch 80 Loss 1.3923\n",
      "Epoch 69 Batch 90 Loss 1.4417\n",
      "Epoch 69 Batch 100 Loss 1.4102\n",
      "Epoch 69 Batch 110 Loss 1.4169\n",
      "Epoch 69 Batch 120 Loss 1.3923\n",
      "Time taken for 1 epoch 23.170552253723145 sec\n",
      "\n",
      "Epoch 70 Batch 0 Loss 1.3459\n",
      "Saved checkpoint for epoch 69: ./training_checkpoints\\ckpt-70\n",
      "Epoch 70 Batch 0 Loss 1.3459\n",
      "Epoch 70 Batch 10 Loss 1.4144\n",
      "Epoch 70 Batch 20 Loss 1.3953\n",
      "Epoch 70 Batch 30 Loss 1.4296\n",
      "Epoch 70 Batch 40 Loss 1.4392\n",
      "Epoch 70 Batch 50 Loss 1.3964\n",
      "Epoch 70 Batch 60 Loss 1.3942\n",
      "Epoch 70 Batch 70 Loss 1.4890\n",
      "Epoch 70 Batch 80 Loss 1.3923\n",
      "Epoch 70 Batch 90 Loss 1.4417\n",
      "Epoch 70 Batch 100 Loss 1.4102\n",
      "Epoch 70 Batch 110 Loss 1.4169\n",
      "Epoch 70 Batch 120 Loss 1.3923\n",
      "Time taken for 1 epoch 23.105403661727905 sec\n",
      "\n",
      "Epoch 71 Batch 0 Loss 1.3460\n",
      "Saved checkpoint for epoch 70: ./training_checkpoints\\ckpt-71\n",
      "Epoch 71 Batch 0 Loss 1.3460\n",
      "Epoch 71 Batch 10 Loss 1.4144\n",
      "Epoch 71 Batch 20 Loss 1.3953\n",
      "Epoch 71 Batch 30 Loss 1.4296\n",
      "Epoch 71 Batch 40 Loss 1.4392\n",
      "Epoch 71 Batch 50 Loss 1.3964\n",
      "Epoch 71 Batch 60 Loss 1.3942\n",
      "Epoch 71 Batch 70 Loss 1.4890\n",
      "Epoch 71 Batch 80 Loss 1.3923\n",
      "Epoch 71 Batch 90 Loss 1.4417\n",
      "Epoch 71 Batch 100 Loss 1.4102\n",
      "Epoch 71 Batch 110 Loss 1.4169\n",
      "Epoch 71 Batch 120 Loss 1.3923\n",
      "Time taken for 1 epoch 24.26400327682495 sec\n",
      "\n",
      "Epoch 72 Batch 0 Loss 1.3460\n",
      "Saved checkpoint for epoch 71: ./training_checkpoints\\ckpt-72\n",
      "Epoch 72 Batch 0 Loss 1.3460\n",
      "Epoch 72 Batch 10 Loss 1.4144\n",
      "Epoch 72 Batch 20 Loss 1.3953\n",
      "Epoch 72 Batch 30 Loss 1.4296\n",
      "Epoch 72 Batch 40 Loss 1.4392\n",
      "Epoch 72 Batch 50 Loss 1.3964\n",
      "Epoch 72 Batch 60 Loss 1.3941\n",
      "Epoch 72 Batch 70 Loss 1.4891\n",
      "Epoch 72 Batch 80 Loss 1.3923\n",
      "Epoch 72 Batch 90 Loss 1.4417\n",
      "Epoch 72 Batch 100 Loss 1.4102\n",
      "Epoch 72 Batch 110 Loss 1.4169\n",
      "Epoch 72 Batch 120 Loss 1.3924\n",
      "Time taken for 1 epoch 23.018193244934082 sec\n",
      "\n",
      "Epoch 73 Batch 0 Loss 1.3461\n",
      "Saved checkpoint for epoch 72: ./training_checkpoints\\ckpt-73\n",
      "Epoch 73 Batch 0 Loss 1.3461\n",
      "Epoch 73 Batch 10 Loss 1.4144\n",
      "Epoch 73 Batch 20 Loss 1.3954\n",
      "Epoch 73 Batch 30 Loss 1.4296\n",
      "Epoch 73 Batch 40 Loss 1.4392\n",
      "Epoch 73 Batch 50 Loss 1.3964\n",
      "Epoch 73 Batch 60 Loss 1.3941\n",
      "Epoch 73 Batch 70 Loss 1.4891\n",
      "Epoch 73 Batch 80 Loss 1.3923\n",
      "Epoch 73 Batch 90 Loss 1.4417\n",
      "Epoch 73 Batch 100 Loss 1.4102\n",
      "Epoch 73 Batch 110 Loss 1.4169\n",
      "Epoch 73 Batch 120 Loss 1.3924\n",
      "Time taken for 1 epoch 24.24369716644287 sec\n",
      "\n",
      "Epoch 74 Batch 0 Loss 1.3462\n",
      "Saved checkpoint for epoch 73: ./training_checkpoints\\ckpt-74\n",
      "Epoch 74 Batch 0 Loss 1.3462\n",
      "Epoch 74 Batch 10 Loss 1.4144\n",
      "Epoch 74 Batch 20 Loss 1.3954\n",
      "Epoch 74 Batch 30 Loss 1.4296\n",
      "Epoch 74 Batch 40 Loss 1.4392\n",
      "Epoch 74 Batch 50 Loss 1.3964\n",
      "Epoch 74 Batch 60 Loss 1.3941\n",
      "Epoch 74 Batch 70 Loss 1.4892\n",
      "Epoch 74 Batch 80 Loss 1.3923\n",
      "Epoch 74 Batch 90 Loss 1.4417\n",
      "Epoch 74 Batch 100 Loss 1.4102\n",
      "Epoch 74 Batch 110 Loss 1.4169\n",
      "Epoch 74 Batch 120 Loss 1.3924\n",
      "Time taken for 1 epoch 22.969974994659424 sec\n",
      "\n",
      "Epoch 75 Batch 0 Loss 1.3462\n",
      "Saved checkpoint for epoch 74: ./training_checkpoints\\ckpt-75\n",
      "Epoch 75 Batch 0 Loss 1.3462\n",
      "Epoch 75 Batch 10 Loss 1.4144\n",
      "Epoch 75 Batch 20 Loss 1.3954\n",
      "Epoch 75 Batch 30 Loss 1.4296\n",
      "Epoch 75 Batch 40 Loss 1.4392\n",
      "Epoch 75 Batch 50 Loss 1.3964\n",
      "Epoch 75 Batch 60 Loss 1.3941\n",
      "Epoch 75 Batch 70 Loss 1.4892\n",
      "Epoch 75 Batch 80 Loss 1.3922\n",
      "Epoch 75 Batch 90 Loss 1.4417\n",
      "Epoch 75 Batch 100 Loss 1.4102\n",
      "Epoch 75 Batch 110 Loss 1.4169\n",
      "Epoch 75 Batch 120 Loss 1.3924\n",
      "Time taken for 1 epoch 23.254990577697754 sec\n",
      "\n",
      "Epoch 76 Batch 0 Loss 1.3463\n",
      "Saved checkpoint for epoch 75: ./training_checkpoints\\ckpt-76\n",
      "Epoch 76 Batch 0 Loss 1.3463\n",
      "Epoch 76 Batch 10 Loss 1.4144\n",
      "Epoch 76 Batch 20 Loss 1.3954\n",
      "Epoch 76 Batch 30 Loss 1.4296\n",
      "Epoch 76 Batch 40 Loss 1.4392\n",
      "Epoch 76 Batch 50 Loss 1.3963\n",
      "Epoch 76 Batch 60 Loss 1.3941\n",
      "Epoch 76 Batch 70 Loss 1.4893\n",
      "Epoch 76 Batch 80 Loss 1.3922\n",
      "Epoch 76 Batch 90 Loss 1.4418\n",
      "Epoch 76 Batch 100 Loss 1.4102\n",
      "Epoch 76 Batch 110 Loss 1.4169\n",
      "Epoch 76 Batch 120 Loss 1.3925\n",
      "Time taken for 1 epoch 25.614742279052734 sec\n",
      "\n",
      "Epoch 77 Batch 0 Loss 1.3464\n",
      "Saved checkpoint for epoch 76: ./training_checkpoints\\ckpt-77\n",
      "Epoch 77 Batch 0 Loss 1.3464\n",
      "Epoch 77 Batch 10 Loss 1.4144\n",
      "Epoch 77 Batch 20 Loss 1.3954\n",
      "Epoch 77 Batch 30 Loss 1.4296\n",
      "Epoch 77 Batch 40 Loss 1.4392\n",
      "Epoch 77 Batch 50 Loss 1.3963\n",
      "Epoch 77 Batch 60 Loss 1.3941\n",
      "Epoch 77 Batch 70 Loss 1.4894\n",
      "Epoch 77 Batch 80 Loss 1.3922\n",
      "Epoch 77 Batch 90 Loss 1.4418\n",
      "Epoch 77 Batch 100 Loss 1.4102\n",
      "Epoch 77 Batch 110 Loss 1.4169\n",
      "Epoch 77 Batch 120 Loss 1.3925\n",
      "Time taken for 1 epoch 22.64697003364563 sec\n",
      "\n",
      "Epoch 78 Batch 0 Loss 1.3465\n",
      "Saved checkpoint for epoch 77: ./training_checkpoints\\ckpt-78\n",
      "Epoch 78 Batch 0 Loss 1.3465\n",
      "Epoch 78 Batch 10 Loss 1.4144\n",
      "Epoch 78 Batch 20 Loss 1.3954\n",
      "Epoch 78 Batch 30 Loss 1.4296\n",
      "Epoch 78 Batch 40 Loss 1.4392\n",
      "Epoch 78 Batch 50 Loss 1.3963\n",
      "Epoch 78 Batch 60 Loss 1.3941\n",
      "Epoch 78 Batch 70 Loss 1.4894\n",
      "Epoch 78 Batch 80 Loss 1.3922\n",
      "Epoch 78 Batch 90 Loss 1.4418\n",
      "Epoch 78 Batch 100 Loss 1.4102\n",
      "Epoch 78 Batch 110 Loss 1.4169\n",
      "Epoch 78 Batch 120 Loss 1.3925\n",
      "Time taken for 1 epoch 22.758408069610596 sec\n",
      "\n",
      "Epoch 79 Batch 0 Loss 1.3466\n",
      "Saved checkpoint for epoch 78: ./training_checkpoints\\ckpt-79\n",
      "Epoch 79 Batch 0 Loss 1.3466\n",
      "Epoch 79 Batch 10 Loss 1.4144\n",
      "Epoch 79 Batch 20 Loss 1.3954\n",
      "Epoch 79 Batch 30 Loss 1.4296\n",
      "Epoch 79 Batch 40 Loss 1.4392\n",
      "Epoch 79 Batch 50 Loss 1.3963\n",
      "Epoch 79 Batch 60 Loss 1.3940\n",
      "Epoch 79 Batch 70 Loss 1.4895\n",
      "Epoch 79 Batch 80 Loss 1.3922\n",
      "Epoch 79 Batch 90 Loss 1.4418\n",
      "Epoch 79 Batch 100 Loss 1.4102\n",
      "Epoch 79 Batch 110 Loss 1.4169\n",
      "Epoch 79 Batch 120 Loss 1.3925\n",
      "Time taken for 1 epoch 22.464092016220093 sec\n",
      "\n",
      "Epoch 80 Batch 0 Loss 1.3467\n",
      "Saved checkpoint for epoch 79: ./training_checkpoints\\ckpt-80\n",
      "Epoch 80 Batch 0 Loss 1.3467\n",
      "Epoch 80 Batch 10 Loss 1.4145\n",
      "Epoch 80 Batch 20 Loss 1.3954\n",
      "Epoch 80 Batch 30 Loss 1.4296\n",
      "Epoch 80 Batch 40 Loss 1.4392\n",
      "Epoch 80 Batch 50 Loss 1.3963\n",
      "Epoch 80 Batch 60 Loss 1.3940\n",
      "Epoch 80 Batch 70 Loss 1.4896\n",
      "Epoch 80 Batch 80 Loss 1.3922\n",
      "Epoch 80 Batch 90 Loss 1.4418\n",
      "Epoch 80 Batch 100 Loss 1.4102\n",
      "Epoch 80 Batch 110 Loss 1.4169\n",
      "Epoch 80 Batch 120 Loss 1.3926\n",
      "Time taken for 1 epoch 22.71251916885376 sec\n",
      "\n",
      "Epoch 81 Batch 0 Loss 1.3468\n",
      "Saved checkpoint for epoch 80: ./training_checkpoints\\ckpt-81\n",
      "Epoch 81 Batch 0 Loss 1.3468\n",
      "Epoch 81 Batch 10 Loss 1.4145\n",
      "Epoch 81 Batch 20 Loss 1.3955\n",
      "Epoch 81 Batch 30 Loss 1.4296\n",
      "Epoch 81 Batch 40 Loss 1.4392\n",
      "Epoch 81 Batch 50 Loss 1.3963\n",
      "Epoch 81 Batch 60 Loss 1.3940\n",
      "Epoch 81 Batch 70 Loss 1.4897\n",
      "Epoch 81 Batch 80 Loss 1.3922\n",
      "Epoch 81 Batch 90 Loss 1.4418\n",
      "Epoch 81 Batch 100 Loss 1.4102\n",
      "Epoch 81 Batch 110 Loss 1.4169\n",
      "Epoch 81 Batch 120 Loss 1.3926\n",
      "Time taken for 1 epoch 22.5534405708313 sec\n",
      "\n",
      "Epoch 82 Batch 0 Loss 1.3469\n",
      "Saved checkpoint for epoch 81: ./training_checkpoints\\ckpt-82\n",
      "Epoch 82 Batch 0 Loss 1.3469\n",
      "Epoch 82 Batch 10 Loss 1.4145\n",
      "Epoch 82 Batch 20 Loss 1.3955\n",
      "Epoch 82 Batch 30 Loss 1.4296\n",
      "Epoch 82 Batch 40 Loss 1.4393\n",
      "Epoch 82 Batch 50 Loss 1.3963\n",
      "Epoch 82 Batch 60 Loss 1.3940\n",
      "Epoch 82 Batch 70 Loss 1.4898\n",
      "Epoch 82 Batch 80 Loss 1.3922\n",
      "Epoch 82 Batch 90 Loss 1.4418\n",
      "Epoch 82 Batch 100 Loss 1.4102\n",
      "Epoch 82 Batch 110 Loss 1.4169\n",
      "Epoch 82 Batch 120 Loss 1.3927\n",
      "Time taken for 1 epoch 22.949320793151855 sec\n",
      "\n",
      "Epoch 83 Batch 0 Loss 1.3470\n",
      "Saved checkpoint for epoch 82: ./training_checkpoints\\ckpt-83\n",
      "Epoch 83 Batch 0 Loss 1.3470\n",
      "Epoch 83 Batch 10 Loss 1.4145\n",
      "Epoch 83 Batch 20 Loss 1.3955\n",
      "Epoch 83 Batch 30 Loss 1.4296\n",
      "Epoch 83 Batch 40 Loss 1.4393\n",
      "Epoch 83 Batch 50 Loss 1.3963\n",
      "Epoch 83 Batch 60 Loss 1.3940\n",
      "Epoch 83 Batch 70 Loss 1.4898\n",
      "Epoch 83 Batch 80 Loss 1.3922\n",
      "Epoch 83 Batch 90 Loss 1.4418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 100 Loss 1.4102\n",
      "Epoch 83 Batch 110 Loss 1.4169\n",
      "Epoch 83 Batch 120 Loss 1.3927\n",
      "Time taken for 1 epoch 23.19150996208191 sec\n",
      "\n",
      "Epoch 84 Batch 0 Loss 1.3471\n",
      "Saved checkpoint for epoch 83: ./training_checkpoints\\ckpt-84\n",
      "Epoch 84 Batch 0 Loss 1.3471\n",
      "Epoch 84 Batch 10 Loss 1.4145\n",
      "Epoch 84 Batch 20 Loss 1.3955\n",
      "Epoch 84 Batch 30 Loss 1.4296\n",
      "Epoch 84 Batch 40 Loss 1.4393\n",
      "Epoch 84 Batch 50 Loss 1.3962\n",
      "Epoch 84 Batch 60 Loss 1.3939\n",
      "Epoch 84 Batch 70 Loss 1.4899\n",
      "Epoch 84 Batch 80 Loss 1.3922\n",
      "Epoch 84 Batch 90 Loss 1.4418\n",
      "Epoch 84 Batch 100 Loss 1.4102\n",
      "Epoch 84 Batch 110 Loss 1.4169\n",
      "Epoch 84 Batch 120 Loss 1.3928\n",
      "Time taken for 1 epoch 22.708664894104004 sec\n",
      "\n",
      "Epoch 85 Batch 0 Loss 1.3472\n",
      "Saved checkpoint for epoch 84: ./training_checkpoints\\ckpt-85\n",
      "Epoch 85 Batch 0 Loss 1.3472\n",
      "Epoch 85 Batch 10 Loss 1.4145\n",
      "Epoch 85 Batch 20 Loss 1.3955\n",
      "Epoch 85 Batch 30 Loss 1.4296\n",
      "Epoch 85 Batch 40 Loss 1.4393\n",
      "Epoch 85 Batch 50 Loss 1.3962\n",
      "Epoch 85 Batch 60 Loss 1.3939\n",
      "Epoch 85 Batch 70 Loss 1.4900\n",
      "Epoch 85 Batch 80 Loss 1.3922\n",
      "Epoch 85 Batch 90 Loss 1.4418\n",
      "Epoch 85 Batch 100 Loss 1.4102\n",
      "Epoch 85 Batch 110 Loss 1.4169\n",
      "Epoch 85 Batch 120 Loss 1.3928\n",
      "Time taken for 1 epoch 22.749104976654053 sec\n",
      "\n",
      "Epoch 86 Batch 0 Loss 1.3474\n",
      "Saved checkpoint for epoch 85: ./training_checkpoints\\ckpt-86\n",
      "Epoch 86 Batch 0 Loss 1.3474\n",
      "Epoch 86 Batch 10 Loss 1.4145\n",
      "Epoch 86 Batch 20 Loss 1.3955\n",
      "Epoch 86 Batch 30 Loss 1.4296\n",
      "Epoch 86 Batch 40 Loss 1.4393\n",
      "Epoch 86 Batch 50 Loss 1.3962\n",
      "Epoch 86 Batch 60 Loss 1.3939\n",
      "Epoch 86 Batch 70 Loss 1.4902\n",
      "Epoch 86 Batch 80 Loss 1.3921\n",
      "Epoch 86 Batch 90 Loss 1.4418\n",
      "Epoch 86 Batch 100 Loss 1.4102\n",
      "Epoch 86 Batch 110 Loss 1.4169\n",
      "Epoch 86 Batch 120 Loss 1.3929\n",
      "Time taken for 1 epoch 23.17566204071045 sec\n",
      "\n",
      "Epoch 87 Batch 0 Loss 1.3475\n",
      "Saved checkpoint for epoch 86: ./training_checkpoints\\ckpt-87\n",
      "Epoch 87 Batch 0 Loss 1.3475\n",
      "Epoch 87 Batch 10 Loss 1.4145\n",
      "Epoch 87 Batch 20 Loss 1.3955\n",
      "Epoch 87 Batch 30 Loss 1.4296\n",
      "Epoch 87 Batch 40 Loss 1.4393\n",
      "Epoch 87 Batch 50 Loss 1.3962\n",
      "Epoch 87 Batch 60 Loss 1.3938\n",
      "Epoch 87 Batch 70 Loss 1.4903\n",
      "Epoch 87 Batch 80 Loss 1.3921\n",
      "Epoch 87 Batch 90 Loss 1.4418\n",
      "Epoch 87 Batch 100 Loss 1.4103\n",
      "Epoch 87 Batch 110 Loss 1.4169\n",
      "Epoch 87 Batch 120 Loss 1.3929\n",
      "Time taken for 1 epoch 22.440670013427734 sec\n",
      "\n",
      "Epoch 88 Batch 0 Loss 1.3477\n",
      "Saved checkpoint for epoch 87: ./training_checkpoints\\ckpt-88\n",
      "Epoch 88 Batch 0 Loss 1.3477\n",
      "Epoch 88 Batch 10 Loss 1.4145\n",
      "Epoch 88 Batch 20 Loss 1.3955\n",
      "Epoch 88 Batch 30 Loss 1.4296\n",
      "Epoch 88 Batch 40 Loss 1.4393\n",
      "Epoch 88 Batch 50 Loss 1.3962\n",
      "Epoch 88 Batch 60 Loss 1.3938\n",
      "Epoch 88 Batch 70 Loss 1.4904\n",
      "Epoch 88 Batch 80 Loss 1.3921\n",
      "Epoch 88 Batch 90 Loss 1.4418\n",
      "Epoch 88 Batch 100 Loss 1.4103\n",
      "Epoch 88 Batch 110 Loss 1.4169\n",
      "Epoch 88 Batch 120 Loss 1.3930\n",
      "Time taken for 1 epoch 23.641844987869263 sec\n",
      "\n",
      "Epoch 89 Batch 0 Loss 1.3478\n",
      "Saved checkpoint for epoch 88: ./training_checkpoints\\ckpt-89\n",
      "Epoch 89 Batch 0 Loss 1.3478\n",
      "Epoch 89 Batch 10 Loss 1.4145\n",
      "Epoch 89 Batch 20 Loss 1.3955\n",
      "Epoch 89 Batch 30 Loss 1.4296\n",
      "Epoch 89 Batch 40 Loss 1.4394\n",
      "Epoch 89 Batch 50 Loss 1.3961\n",
      "Epoch 89 Batch 60 Loss 1.3938\n",
      "Epoch 89 Batch 70 Loss 1.4905\n",
      "Epoch 89 Batch 80 Loss 1.3921\n",
      "Epoch 89 Batch 90 Loss 1.4418\n",
      "Epoch 89 Batch 100 Loss 1.4103\n",
      "Epoch 89 Batch 110 Loss 1.4169\n",
      "Epoch 89 Batch 120 Loss 1.3930\n",
      "Time taken for 1 epoch 22.642017126083374 sec\n",
      "\n",
      "Epoch 90 Batch 0 Loss 1.3480\n",
      "Saved checkpoint for epoch 89: ./training_checkpoints\\ckpt-90\n",
      "Epoch 90 Batch 0 Loss 1.3480\n",
      "Epoch 90 Batch 10 Loss 1.4145\n",
      "Epoch 90 Batch 20 Loss 1.3956\n",
      "Epoch 90 Batch 30 Loss 1.4296\n",
      "Epoch 90 Batch 40 Loss 1.4394\n",
      "Epoch 90 Batch 50 Loss 1.3961\n",
      "Epoch 90 Batch 60 Loss 1.3937\n",
      "Epoch 90 Batch 70 Loss 1.4907\n",
      "Epoch 90 Batch 80 Loss 1.3921\n",
      "Epoch 90 Batch 90 Loss 1.4418\n",
      "Epoch 90 Batch 100 Loss 1.4103\n",
      "Epoch 90 Batch 110 Loss 1.4169\n",
      "Epoch 90 Batch 120 Loss 1.3931\n",
      "Time taken for 1 epoch 23.488755702972412 sec\n",
      "\n",
      "Epoch 91 Batch 0 Loss 1.3482\n",
      "Saved checkpoint for epoch 90: ./training_checkpoints\\ckpt-91\n",
      "Epoch 91 Batch 0 Loss 1.3482\n",
      "Epoch 91 Batch 10 Loss 1.4146\n",
      "Epoch 91 Batch 20 Loss 1.3956\n",
      "Epoch 91 Batch 30 Loss 1.4296\n",
      "Epoch 91 Batch 40 Loss 1.4394\n",
      "Epoch 91 Batch 50 Loss 1.3961\n",
      "Epoch 91 Batch 60 Loss 1.3937\n",
      "Epoch 91 Batch 70 Loss 1.4908\n",
      "Epoch 91 Batch 80 Loss 1.3921\n",
      "Epoch 91 Batch 90 Loss 1.4418\n",
      "Epoch 91 Batch 100 Loss 1.4103\n",
      "Epoch 91 Batch 110 Loss 1.4169\n",
      "Epoch 91 Batch 120 Loss 1.3932\n",
      "Time taken for 1 epoch 22.508720636367798 sec\n",
      "\n",
      "Epoch 92 Batch 0 Loss 1.3483\n",
      "Saved checkpoint for epoch 91: ./training_checkpoints\\ckpt-92\n",
      "Epoch 92 Batch 0 Loss 1.3483\n",
      "Epoch 92 Batch 10 Loss 1.4146\n",
      "Epoch 92 Batch 20 Loss 1.3956\n",
      "Epoch 92 Batch 30 Loss 1.4296\n",
      "Epoch 92 Batch 40 Loss 1.4394\n",
      "Epoch 92 Batch 50 Loss 1.3961\n",
      "Epoch 92 Batch 60 Loss 1.3937\n",
      "Epoch 92 Batch 70 Loss 1.4909\n",
      "Epoch 92 Batch 80 Loss 1.3921\n",
      "Epoch 92 Batch 90 Loss 1.4418\n",
      "Epoch 92 Batch 100 Loss 1.4103\n",
      "Epoch 92 Batch 110 Loss 1.4169\n",
      "Epoch 92 Batch 120 Loss 1.3932\n",
      "Time taken for 1 epoch 22.79001474380493 sec\n",
      "\n",
      "Epoch 93 Batch 0 Loss 1.3485\n",
      "Saved checkpoint for epoch 92: ./training_checkpoints\\ckpt-93\n",
      "Epoch 93 Batch 0 Loss 1.3485\n",
      "Epoch 93 Batch 10 Loss 1.4146\n",
      "Epoch 93 Batch 20 Loss 1.3956\n",
      "Epoch 93 Batch 30 Loss 1.4296\n",
      "Epoch 93 Batch 40 Loss 1.4395\n",
      "Epoch 93 Batch 50 Loss 1.3960\n",
      "Epoch 93 Batch 60 Loss 1.3936\n",
      "Epoch 93 Batch 70 Loss 1.4911\n",
      "Epoch 93 Batch 80 Loss 1.3921\n",
      "Epoch 93 Batch 90 Loss 1.4418\n",
      "Epoch 93 Batch 100 Loss 1.4104\n",
      "Epoch 93 Batch 110 Loss 1.4169\n",
      "Epoch 93 Batch 120 Loss 1.3933\n",
      "Time taken for 1 epoch 23.094409942626953 sec\n",
      "\n",
      "Epoch 94 Batch 0 Loss 1.3487\n",
      "Saved checkpoint for epoch 93: ./training_checkpoints\\ckpt-94\n",
      "Epoch 94 Batch 0 Loss 1.3487\n",
      "Epoch 94 Batch 10 Loss 1.4146\n",
      "Epoch 94 Batch 20 Loss 1.3956\n",
      "Epoch 94 Batch 30 Loss 1.4296\n",
      "Epoch 94 Batch 40 Loss 1.4395\n",
      "Epoch 94 Batch 50 Loss 1.3960\n",
      "Epoch 94 Batch 60 Loss 1.3936\n",
      "Epoch 94 Batch 70 Loss 1.4912\n",
      "Epoch 94 Batch 80 Loss 1.3920\n",
      "Epoch 94 Batch 90 Loss 1.4418\n",
      "Epoch 94 Batch 100 Loss 1.4104\n",
      "Epoch 94 Batch 110 Loss 1.4169\n",
      "Epoch 94 Batch 120 Loss 1.3934\n",
      "Time taken for 1 epoch 22.04060196876526 sec\n",
      "\n",
      "Epoch 95 Batch 0 Loss 1.3489\n",
      "Saved checkpoint for epoch 94: ./training_checkpoints\\ckpt-95\n",
      "Epoch 95 Batch 0 Loss 1.3489\n",
      "Epoch 95 Batch 10 Loss 1.4146\n",
      "Epoch 95 Batch 20 Loss 1.3956\n",
      "Epoch 95 Batch 30 Loss 1.4296\n",
      "Epoch 95 Batch 40 Loss 1.4395\n",
      "Epoch 95 Batch 50 Loss 1.3960\n",
      "Epoch 95 Batch 60 Loss 1.3936\n",
      "Epoch 95 Batch 70 Loss 1.4914\n",
      "Epoch 95 Batch 80 Loss 1.3920\n",
      "Epoch 95 Batch 90 Loss 1.4418\n",
      "Epoch 95 Batch 100 Loss 1.4104\n",
      "Epoch 95 Batch 110 Loss 1.4169\n",
      "Epoch 95 Batch 120 Loss 1.3935\n",
      "Time taken for 1 epoch 22.958977937698364 sec\n",
      "\n",
      "Epoch 96 Batch 0 Loss 1.3491\n",
      "Saved checkpoint for epoch 95: ./training_checkpoints\\ckpt-96\n",
      "Epoch 96 Batch 0 Loss 1.3491\n",
      "Epoch 96 Batch 10 Loss 1.4146\n",
      "Epoch 96 Batch 20 Loss 1.3956\n",
      "Epoch 96 Batch 30 Loss 1.4296\n",
      "Epoch 96 Batch 40 Loss 1.4396\n",
      "Epoch 96 Batch 50 Loss 1.3959\n",
      "Epoch 96 Batch 60 Loss 1.3935\n",
      "Epoch 96 Batch 70 Loss 1.4916\n",
      "Epoch 96 Batch 80 Loss 1.3920\n",
      "Epoch 96 Batch 90 Loss 1.4418\n",
      "Epoch 96 Batch 100 Loss 1.4104\n",
      "Epoch 96 Batch 110 Loss 1.4169\n",
      "Epoch 96 Batch 120 Loss 1.3936\n",
      "Time taken for 1 epoch 22.859679222106934 sec\n",
      "\n",
      "Epoch 97 Batch 0 Loss 1.3493\n",
      "Saved checkpoint for epoch 96: ./training_checkpoints\\ckpt-97\n",
      "Epoch 97 Batch 0 Loss 1.3493\n",
      "Epoch 97 Batch 10 Loss 1.4146\n",
      "Epoch 97 Batch 20 Loss 1.3956\n",
      "Epoch 97 Batch 30 Loss 1.4296\n",
      "Epoch 97 Batch 40 Loss 1.4396\n",
      "Epoch 97 Batch 50 Loss 1.3959\n",
      "Epoch 97 Batch 60 Loss 1.3935\n",
      "Epoch 97 Batch 70 Loss 1.4917\n",
      "Epoch 97 Batch 80 Loss 1.3920\n",
      "Epoch 97 Batch 90 Loss 1.4418\n",
      "Epoch 97 Batch 100 Loss 1.4105\n",
      "Epoch 97 Batch 110 Loss 1.4169\n",
      "Epoch 97 Batch 120 Loss 1.3937\n",
      "Time taken for 1 epoch 23.293426275253296 sec\n",
      "\n",
      "Epoch 98 Batch 0 Loss 1.3496\n",
      "Saved checkpoint for epoch 97: ./training_checkpoints\\ckpt-98\n",
      "Epoch 98 Batch 0 Loss 1.3496\n",
      "Epoch 98 Batch 10 Loss 1.4146\n",
      "Epoch 98 Batch 20 Loss 1.3955\n",
      "Epoch 98 Batch 30 Loss 1.4296\n",
      "Epoch 98 Batch 40 Loss 1.4397\n",
      "Epoch 98 Batch 50 Loss 1.3959\n",
      "Epoch 98 Batch 60 Loss 1.3934\n",
      "Epoch 98 Batch 70 Loss 1.4919\n",
      "Epoch 98 Batch 80 Loss 1.3920\n",
      "Epoch 98 Batch 90 Loss 1.4418\n",
      "Epoch 98 Batch 100 Loss 1.4105\n",
      "Epoch 98 Batch 110 Loss 1.4169\n",
      "Epoch 98 Batch 120 Loss 1.3938\n",
      "Time taken for 1 epoch 23.248615980148315 sec\n",
      "\n",
      "Epoch 99 Batch 0 Loss 1.3498\n",
      "Saved checkpoint for epoch 98: ./training_checkpoints\\ckpt-99\n",
      "Epoch 99 Batch 0 Loss 1.3498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 10 Loss 1.4147\n",
      "Epoch 99 Batch 20 Loss 1.3955\n",
      "Epoch 99 Batch 30 Loss 1.4296\n",
      "Epoch 99 Batch 40 Loss 1.4397\n",
      "Epoch 99 Batch 50 Loss 1.3958\n",
      "Epoch 99 Batch 60 Loss 1.3934\n",
      "Epoch 99 Batch 70 Loss 1.4921\n",
      "Epoch 99 Batch 80 Loss 1.3920\n",
      "Epoch 99 Batch 90 Loss 1.4418\n",
      "Epoch 99 Batch 100 Loss 1.4105\n",
      "Epoch 99 Batch 110 Loss 1.4169\n",
      "Epoch 99 Batch 120 Loss 1.3939\n",
      "Time taken for 1 epoch 22.76457905769348 sec\n",
      "\n",
      "Epoch 100 Batch 0 Loss 1.3500\n",
      "Saved checkpoint for epoch 99: ./training_checkpoints\\ckpt-100\n",
      "Epoch 100 Batch 0 Loss 1.3500\n",
      "Epoch 100 Batch 10 Loss 1.4147\n",
      "Epoch 100 Batch 20 Loss 1.3955\n",
      "Epoch 100 Batch 30 Loss 1.4297\n",
      "Epoch 100 Batch 40 Loss 1.4398\n",
      "Epoch 100 Batch 50 Loss 1.3958\n",
      "Epoch 100 Batch 60 Loss 1.3933\n",
      "Epoch 100 Batch 70 Loss 1.4923\n",
      "Epoch 100 Batch 80 Loss 1.3920\n",
      "Epoch 100 Batch 90 Loss 1.4417\n",
      "Epoch 100 Batch 100 Loss 1.4106\n",
      "Epoch 100 Batch 110 Loss 1.4169\n",
      "Epoch 100 Batch 120 Loss 1.3940\n",
      "Time taken for 1 epoch 23.04804039001465 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (L,mels)) in enumerate(pad_batch.take(steps_per_epoch)):\n",
    "        prev_max_attentions = tf.ones(shape=(hp.B,), dtype=tf.int32)\n",
    "        gts = tf.convert_to_tensor(guided_attention())\n",
    "        S = tf.concat((tf.zeros_like(mels[:, :1, :]), mels[:, :-1, :]), 1)\n",
    "\n",
    "        batch_loss,alignments = train_step(L, mels,prev_max_attentions)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        \n",
    "        \n",
    "        if batch % 10 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                           batch,\n",
    "                                                           batch_loss.numpy()))\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "        if int(batch) % 500 == 0:\n",
    "            save_path = manager.save()\n",
    "            print(\"Saved checkpoint for epoch {}: {}\".format(int(epoch), save_path))\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                           batch,\n",
    "                                                           batch_loss.numpy()))\n",
    "\n",
    "            plot_alignment(alignments[0], int(epoch), hp.logdir)\n",
    "\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssrn = SSRN()\n",
    "steps_per_epoch = len(text2mel_data)//16\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,\n",
    "    beta_1=0.9)\n",
    "\n",
    "\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1),optimizer=optimizer,\n",
    "                                 ssrn = ssrn)\n",
    "manager = tf.train.CheckpointManager(ckpt, './training_checkpoints_SSRN', max_to_keep=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step_SSRN(mels,mags):   \n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        Z_logits, Z = ssrn(mels)\n",
    "        \n",
    "\n",
    "        loss_mags = tf.reduce_mean(tf.abs(Z - mags))\n",
    "\n",
    "        # mag binary divergence loss\n",
    "        loss_bd2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Z_logits, labels=mags))\n",
    "\n",
    "        # total loss\n",
    "        loss = loss_mags + loss_bd2\n",
    "\n",
    "\n",
    "    variables = ssrn.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    gradients = [(tf.clip_by_value(grad, -1.0, 1.0))\n",
    "                                  for grad in gradients]\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    loss += loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing from scratch.\n",
      "Epoch 1 Batch 0 Loss 1.9806\n",
      "Saved checkpoint for epoch 0: ./training_checkpoints_SSRN\\ckpt-1\n",
      "Epoch 1 Batch 0 Loss 1.9806\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 10 Loss 1.7512\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 20 Loss 2.0388\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 13 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 30 Loss 2.6817\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 40 Loss 1.7402\n",
      "WARNING:tensorflow:8 out of the last 14 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 50 Loss 1.4738\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 15 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 60 Loss 1.2214\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 14 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 70 Loss 1.5197\n",
      "WARNING:tensorflow:7 out of the last 12 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 13 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 80 Loss 1.3040\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 12 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 90 Loss 1.4842\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 100 Loss 1.3959\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 110 Loss 2.7035\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step_SSRN at 0x000002064E2F9828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch 1 Batch 120 Loss 1.8639\n",
      "Time taken for 1 epoch 268.460209608078 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.9366\n",
      "Saved checkpoint for epoch 1: ./training_checkpoints_SSRN\\ckpt-2\n",
      "Epoch 2 Batch 0 Loss 1.9366\n",
      "Epoch 2 Batch 10 Loss 1.8291\n",
      "Epoch 2 Batch 20 Loss 1.8701\n",
      "Epoch 2 Batch 30 Loss 1.7956\n",
      "Epoch 2 Batch 40 Loss 1.7612\n",
      "Epoch 2 Batch 50 Loss 1.8239\n",
      "Epoch 2 Batch 60 Loss 1.8389\n",
      "Epoch 2 Batch 70 Loss 1.7410\n",
      "Epoch 2 Batch 80 Loss 1.7857\n",
      "Epoch 2 Batch 90 Loss 1.7610\n",
      "Epoch 2 Batch 100 Loss 1.8004\n",
      "Epoch 2 Batch 110 Loss 1.7623\n",
      "Epoch 2 Batch 120 Loss 1.8047\n",
      "Time taken for 1 epoch 34.04882788658142 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.8555\n",
      "Saved checkpoint for epoch 2: ./training_checkpoints_SSRN\\ckpt-3\n",
      "Epoch 3 Batch 0 Loss 1.8555\n",
      "Epoch 3 Batch 10 Loss 1.7829\n",
      "Epoch 3 Batch 20 Loss 1.8165\n",
      "Epoch 3 Batch 30 Loss 1.7656\n",
      "Epoch 3 Batch 40 Loss 1.7342\n",
      "Epoch 3 Batch 50 Loss 1.7804\n",
      "Epoch 3 Batch 60 Loss 1.7929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 70 Loss 1.7359\n",
      "Epoch 3 Batch 80 Loss 1.7514\n",
      "Epoch 3 Batch 90 Loss 1.7451\n",
      "Epoch 3 Batch 100 Loss 1.7712\n",
      "Epoch 3 Batch 110 Loss 1.7378\n",
      "Epoch 3 Batch 120 Loss 1.7734\n",
      "Time taken for 1 epoch 33.88570189476013 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.8087\n",
      "Saved checkpoint for epoch 3: ./training_checkpoints_SSRN\\ckpt-4\n",
      "Epoch 4 Batch 0 Loss 1.8087\n",
      "Epoch 4 Batch 10 Loss 1.7599\n",
      "Epoch 4 Batch 20 Loss 1.7877\n",
      "Epoch 4 Batch 30 Loss 1.7529\n",
      "Epoch 4 Batch 40 Loss 1.7234\n",
      "Epoch 4 Batch 50 Loss 1.7578\n",
      "Epoch 4 Batch 60 Loss 1.7683\n",
      "Epoch 4 Batch 70 Loss 1.7386\n",
      "Epoch 4 Batch 80 Loss 1.7345\n",
      "Epoch 4 Batch 90 Loss 1.7400\n",
      "Epoch 4 Batch 100 Loss 1.7568\n",
      "Epoch 4 Batch 110 Loss 1.7262\n",
      "Epoch 4 Batch 120 Loss 1.7575\n",
      "Time taken for 1 epoch 33.62468409538269 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.7826\n",
      "Saved checkpoint for epoch 4: ./training_checkpoints_SSRN\\ckpt-5\n",
      "Epoch 5 Batch 0 Loss 1.7826\n",
      "Epoch 5 Batch 10 Loss 1.7488\n",
      "Epoch 5 Batch 20 Loss 1.7729\n",
      "Epoch 5 Batch 30 Loss 1.7478\n",
      "Epoch 5 Batch 40 Loss 1.7195\n",
      "Epoch 5 Batch 50 Loss 1.7464\n",
      "Epoch 5 Batch 60 Loss 1.7555\n",
      "Epoch 5 Batch 70 Loss 1.7422\n",
      "Epoch 5 Batch 80 Loss 1.7262\n",
      "Epoch 5 Batch 90 Loss 1.7386\n",
      "Epoch 5 Batch 100 Loss 1.7496\n",
      "Epoch 5 Batch 110 Loss 1.7207\n",
      "Epoch 5 Batch 120 Loss 1.7493\n",
      "Time taken for 1 epoch 34.62167167663574 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.7688\n",
      "Saved checkpoint for epoch 5: ./training_checkpoints_SSRN\\ckpt-6\n",
      "Epoch 6 Batch 0 Loss 1.7688\n",
      "Epoch 6 Batch 10 Loss 1.7434\n",
      "Epoch 6 Batch 20 Loss 1.7652\n",
      "Epoch 6 Batch 30 Loss 1.7455\n",
      "Epoch 6 Batch 40 Loss 1.7179\n",
      "Epoch 6 Batch 50 Loss 1.7405\n",
      "Epoch 6 Batch 60 Loss 1.7489\n",
      "Epoch 6 Batch 70 Loss 1.7444\n",
      "Epoch 6 Batch 80 Loss 1.7219\n",
      "Epoch 6 Batch 90 Loss 1.7380\n",
      "Epoch 6 Batch 100 Loss 1.7458\n",
      "Epoch 6 Batch 110 Loss 1.7178\n",
      "Epoch 6 Batch 120 Loss 1.7450\n",
      "Time taken for 1 epoch 34.050917863845825 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.7615\n",
      "Saved checkpoint for epoch 6: ./training_checkpoints_SSRN\\ckpt-7\n",
      "Epoch 7 Batch 0 Loss 1.7615\n",
      "Epoch 7 Batch 10 Loss 1.7406\n",
      "Epoch 7 Batch 20 Loss 1.7612\n",
      "Epoch 7 Batch 30 Loss 1.7442\n",
      "Epoch 7 Batch 40 Loss 1.7169\n",
      "Epoch 7 Batch 50 Loss 1.7374\n",
      "Epoch 7 Batch 60 Loss 1.7453\n",
      "Epoch 7 Batch 70 Loss 1.7455\n",
      "Epoch 7 Batch 80 Loss 1.7195\n",
      "Epoch 7 Batch 90 Loss 1.7374\n",
      "Epoch 7 Batch 100 Loss 1.7436\n",
      "Epoch 7 Batch 110 Loss 1.7162\n",
      "Epoch 7 Batch 120 Loss 1.7426\n",
      "Time taken for 1 epoch 34.08390998840332 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.7576\n",
      "Saved checkpoint for epoch 7: ./training_checkpoints_SSRN\\ckpt-8\n",
      "Epoch 8 Batch 0 Loss 1.7576\n",
      "Epoch 8 Batch 10 Loss 1.7390\n",
      "Epoch 8 Batch 20 Loss 1.7590\n",
      "Epoch 8 Batch 30 Loss 1.7433\n",
      "Epoch 8 Batch 40 Loss 1.7162\n",
      "Epoch 8 Batch 50 Loss 1.7355\n",
      "Epoch 8 Batch 60 Loss 1.7433\n",
      "Epoch 8 Batch 70 Loss 1.7459\n",
      "Epoch 8 Batch 80 Loss 1.7180\n",
      "Epoch 8 Batch 90 Loss 1.7370\n",
      "Epoch 8 Batch 100 Loss 1.7423\n",
      "Epoch 8 Batch 110 Loss 1.7151\n",
      "Epoch 8 Batch 120 Loss 1.7412\n",
      "Time taken for 1 epoch 34.742915630340576 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.7555\n",
      "Saved checkpoint for epoch 8: ./training_checkpoints_SSRN\\ckpt-9\n",
      "Epoch 9 Batch 0 Loss 1.7555\n",
      "Epoch 9 Batch 10 Loss 1.7381\n",
      "Epoch 9 Batch 20 Loss 1.7578\n",
      "Epoch 9 Batch 30 Loss 1.7426\n",
      "Epoch 9 Batch 40 Loss 1.7157\n",
      "Epoch 9 Batch 50 Loss 1.7344\n",
      "Epoch 9 Batch 60 Loss 1.7421\n",
      "Epoch 9 Batch 70 Loss 1.7460\n",
      "Epoch 9 Batch 80 Loss 1.7171\n",
      "Epoch 9 Batch 90 Loss 1.7366\n",
      "Epoch 9 Batch 100 Loss 1.7414\n",
      "Epoch 9 Batch 110 Loss 1.7145\n",
      "Epoch 9 Batch 120 Loss 1.7404\n",
      "Time taken for 1 epoch 35.13106036186218 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.7543\n",
      "Saved checkpoint for epoch 9: ./training_checkpoints_SSRN\\ckpt-10\n",
      "Epoch 10 Batch 0 Loss 1.7543\n",
      "Epoch 10 Batch 10 Loss 1.7375\n",
      "Epoch 10 Batch 20 Loss 1.7570\n",
      "Epoch 10 Batch 30 Loss 1.7422\n",
      "Epoch 10 Batch 40 Loss 1.7154\n",
      "Epoch 10 Batch 50 Loss 1.7338\n",
      "Epoch 10 Batch 60 Loss 1.7413\n",
      "Epoch 10 Batch 70 Loss 1.7461\n",
      "Epoch 10 Batch 80 Loss 1.7165\n",
      "Epoch 10 Batch 90 Loss 1.7364\n",
      "Epoch 10 Batch 100 Loss 1.7409\n",
      "Epoch 10 Batch 110 Loss 1.7141\n",
      "Epoch 10 Batch 120 Loss 1.7399\n",
      "Time taken for 1 epoch 34.90671110153198 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.7536\n",
      "Saved checkpoint for epoch 10: ./training_checkpoints_SSRN\\ckpt-11\n",
      "Epoch 11 Batch 0 Loss 1.7536\n",
      "Epoch 11 Batch 10 Loss 1.7372\n",
      "Epoch 11 Batch 20 Loss 1.7565\n",
      "Epoch 11 Batch 30 Loss 1.7419\n",
      "Epoch 11 Batch 40 Loss 1.7152\n",
      "Epoch 11 Batch 50 Loss 1.7333\n",
      "Epoch 11 Batch 60 Loss 1.7408\n",
      "Epoch 11 Batch 70 Loss 1.7461\n",
      "Epoch 11 Batch 80 Loss 1.7161\n",
      "Epoch 11 Batch 90 Loss 1.7362\n",
      "Epoch 11 Batch 100 Loss 1.7405\n",
      "Epoch 11 Batch 110 Loss 1.7138\n",
      "Epoch 11 Batch 120 Loss 1.7395\n",
      "Time taken for 1 epoch 34.570600271224976 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.7532\n",
      "Saved checkpoint for epoch 11: ./training_checkpoints_SSRN\\ckpt-12\n",
      "Epoch 12 Batch 0 Loss 1.7532\n",
      "Epoch 12 Batch 10 Loss 1.7369\n",
      "Epoch 12 Batch 20 Loss 1.7562\n",
      "Epoch 12 Batch 30 Loss 1.7417\n",
      "Epoch 12 Batch 40 Loss 1.7150\n",
      "Epoch 12 Batch 50 Loss 1.7330\n",
      "Epoch 12 Batch 60 Loss 1.7405\n",
      "Epoch 12 Batch 70 Loss 1.7462\n",
      "Epoch 12 Batch 80 Loss 1.7159\n",
      "Epoch 12 Batch 90 Loss 1.7361\n",
      "Epoch 12 Batch 100 Loss 1.7403\n",
      "Epoch 12 Batch 110 Loss 1.7136\n",
      "Epoch 12 Batch 120 Loss 1.7393\n",
      "Time taken for 1 epoch 35.140692949295044 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.7529\n",
      "Saved checkpoint for epoch 12: ./training_checkpoints_SSRN\\ckpt-13\n",
      "Epoch 13 Batch 0 Loss 1.7529\n",
      "Epoch 13 Batch 10 Loss 1.7368\n",
      "Epoch 13 Batch 20 Loss 1.7560\n",
      "Epoch 13 Batch 30 Loss 1.7415\n",
      "Epoch 13 Batch 40 Loss 1.7149\n",
      "Epoch 13 Batch 50 Loss 1.7328\n",
      "Epoch 13 Batch 60 Loss 1.7403\n",
      "Epoch 13 Batch 70 Loss 1.7463\n",
      "Epoch 13 Batch 80 Loss 1.7157\n",
      "Epoch 13 Batch 90 Loss 1.7361\n",
      "Epoch 13 Batch 100 Loss 1.7401\n",
      "Epoch 13 Batch 110 Loss 1.7135\n",
      "Epoch 13 Batch 120 Loss 1.7392\n",
      "Time taken for 1 epoch 35.11830186843872 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.7527\n",
      "Saved checkpoint for epoch 13: ./training_checkpoints_SSRN\\ckpt-14\n",
      "Epoch 14 Batch 0 Loss 1.7527\n",
      "Epoch 14 Batch 10 Loss 1.7367\n",
      "Epoch 14 Batch 20 Loss 1.7559\n",
      "Epoch 14 Batch 30 Loss 1.7415\n",
      "Epoch 14 Batch 40 Loss 1.7149\n",
      "Epoch 14 Batch 50 Loss 1.7327\n",
      "Epoch 14 Batch 60 Loss 1.7401\n",
      "Epoch 14 Batch 70 Loss 1.7464\n",
      "Epoch 14 Batch 80 Loss 1.7156\n",
      "Epoch 14 Batch 90 Loss 1.7361\n",
      "Epoch 14 Batch 100 Loss 1.7400\n",
      "Epoch 14 Batch 110 Loss 1.7135\n",
      "Epoch 14 Batch 120 Loss 1.7391\n",
      "Time taken for 1 epoch 34.72245526313782 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 1.7526\n",
      "Saved checkpoint for epoch 14: ./training_checkpoints_SSRN\\ckpt-15\n",
      "Epoch 15 Batch 0 Loss 1.7526\n",
      "Epoch 15 Batch 10 Loss 1.7367\n",
      "Epoch 15 Batch 20 Loss 1.7558\n",
      "Epoch 15 Batch 30 Loss 1.7414\n",
      "Epoch 15 Batch 40 Loss 1.7149\n",
      "Epoch 15 Batch 50 Loss 1.7326\n",
      "Epoch 15 Batch 60 Loss 1.7400\n",
      "Epoch 15 Batch 70 Loss 1.7465\n",
      "Epoch 15 Batch 80 Loss 1.7155\n",
      "Epoch 15 Batch 90 Loss 1.7361\n",
      "Epoch 15 Batch 100 Loss 1.7400\n",
      "Epoch 15 Batch 110 Loss 1.7134\n",
      "Epoch 15 Batch 120 Loss 1.7390\n",
      "Time taken for 1 epoch 34.262988805770874 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 1.7525\n",
      "Saved checkpoint for epoch 15: ./training_checkpoints_SSRN\\ckpt-16\n",
      "Epoch 16 Batch 0 Loss 1.7525\n",
      "Epoch 16 Batch 10 Loss 1.7366\n",
      "Epoch 16 Batch 20 Loss 1.7558\n",
      "Epoch 16 Batch 30 Loss 1.7414\n",
      "Epoch 16 Batch 40 Loss 1.7148\n",
      "Epoch 16 Batch 50 Loss 1.7325\n",
      "Epoch 16 Batch 60 Loss 1.7399\n",
      "Epoch 16 Batch 70 Loss 1.7466\n",
      "Epoch 16 Batch 80 Loss 1.7154\n",
      "Epoch 16 Batch 90 Loss 1.7361\n",
      "Epoch 16 Batch 100 Loss 1.7399\n",
      "Epoch 16 Batch 110 Loss 1.7134\n",
      "Epoch 16 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 35.23269844055176 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 1.7524\n",
      "Saved checkpoint for epoch 16: ./training_checkpoints_SSRN\\ckpt-17\n",
      "Epoch 17 Batch 0 Loss 1.7524\n",
      "Epoch 17 Batch 10 Loss 1.7366\n",
      "Epoch 17 Batch 20 Loss 1.7557\n",
      "Epoch 17 Batch 30 Loss 1.7414\n",
      "Epoch 17 Batch 40 Loss 1.7148\n",
      "Epoch 17 Batch 50 Loss 1.7325\n",
      "Epoch 17 Batch 60 Loss 1.7398\n",
      "Epoch 17 Batch 70 Loss 1.7466\n",
      "Epoch 17 Batch 80 Loss 1.7154\n",
      "Epoch 17 Batch 90 Loss 1.7361\n",
      "Epoch 17 Batch 100 Loss 1.7399\n",
      "Epoch 17 Batch 110 Loss 1.7134\n",
      "Epoch 17 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 35.00306820869446 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 1.7524\n",
      "Saved checkpoint for epoch 17: ./training_checkpoints_SSRN\\ckpt-18\n",
      "Epoch 18 Batch 0 Loss 1.7524\n",
      "Epoch 18 Batch 10 Loss 1.7366\n",
      "Epoch 18 Batch 20 Loss 1.7557\n",
      "Epoch 18 Batch 30 Loss 1.7413\n",
      "Epoch 18 Batch 40 Loss 1.7148\n",
      "Epoch 18 Batch 50 Loss 1.7324\n",
      "Epoch 18 Batch 60 Loss 1.7398\n",
      "Epoch 18 Batch 70 Loss 1.7467\n",
      "Epoch 18 Batch 80 Loss 1.7154\n",
      "Epoch 18 Batch 90 Loss 1.7361\n",
      "Epoch 18 Batch 100 Loss 1.7398\n",
      "Epoch 18 Batch 110 Loss 1.7134\n",
      "Epoch 18 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 34.372833490371704 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 1.7524\n",
      "Saved checkpoint for epoch 18: ./training_checkpoints_SSRN\\ckpt-19\n",
      "Epoch 19 Batch 0 Loss 1.7524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 10 Loss 1.7366\n",
      "Epoch 19 Batch 20 Loss 1.7557\n",
      "Epoch 19 Batch 30 Loss 1.7413\n",
      "Epoch 19 Batch 40 Loss 1.7148\n",
      "Epoch 19 Batch 50 Loss 1.7324\n",
      "Epoch 19 Batch 60 Loss 1.7397\n",
      "Epoch 19 Batch 70 Loss 1.7467\n",
      "Epoch 19 Batch 80 Loss 1.7153\n",
      "Epoch 19 Batch 90 Loss 1.7361\n",
      "Epoch 19 Batch 100 Loss 1.7398\n",
      "Epoch 19 Batch 110 Loss 1.7134\n",
      "Epoch 19 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 34.86060333251953 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 1.7524\n",
      "Saved checkpoint for epoch 19: ./training_checkpoints_SSRN\\ckpt-20\n",
      "Epoch 20 Batch 0 Loss 1.7524\n",
      "Epoch 20 Batch 10 Loss 1.7366\n",
      "Epoch 20 Batch 20 Loss 1.7557\n",
      "Epoch 20 Batch 30 Loss 1.7413\n",
      "Epoch 20 Batch 40 Loss 1.7148\n",
      "Epoch 20 Batch 50 Loss 1.7324\n",
      "Epoch 20 Batch 60 Loss 1.7397\n",
      "Epoch 20 Batch 70 Loss 1.7468\n",
      "Epoch 20 Batch 80 Loss 1.7153\n",
      "Epoch 20 Batch 90 Loss 1.7361\n",
      "Epoch 20 Batch 100 Loss 1.7398\n",
      "Epoch 20 Batch 110 Loss 1.7133\n",
      "Epoch 20 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 34.40512132644653 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 1.7524\n",
      "Saved checkpoint for epoch 20: ./training_checkpoints_SSRN\\ckpt-21\n",
      "Epoch 21 Batch 0 Loss 1.7524\n",
      "Epoch 21 Batch 10 Loss 1.7366\n",
      "Epoch 21 Batch 20 Loss 1.7557\n",
      "Epoch 21 Batch 30 Loss 1.7413\n",
      "Epoch 21 Batch 40 Loss 1.7148\n",
      "Epoch 21 Batch 50 Loss 1.7324\n",
      "Epoch 21 Batch 60 Loss 1.7397\n",
      "Epoch 21 Batch 70 Loss 1.7468\n",
      "Epoch 21 Batch 80 Loss 1.7153\n",
      "Epoch 21 Batch 90 Loss 1.7361\n",
      "Epoch 21 Batch 100 Loss 1.7398\n",
      "Epoch 21 Batch 110 Loss 1.7133\n",
      "Epoch 21 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 35.25892233848572 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 1.7524\n",
      "Saved checkpoint for epoch 21: ./training_checkpoints_SSRN\\ckpt-22\n",
      "Epoch 22 Batch 0 Loss 1.7524\n",
      "Epoch 22 Batch 10 Loss 1.7366\n",
      "Epoch 22 Batch 20 Loss 1.7557\n",
      "Epoch 22 Batch 30 Loss 1.7413\n",
      "Epoch 22 Batch 40 Loss 1.7148\n",
      "Epoch 22 Batch 50 Loss 1.7324\n",
      "Epoch 22 Batch 60 Loss 1.7397\n",
      "Epoch 22 Batch 70 Loss 1.7469\n",
      "Epoch 22 Batch 80 Loss 1.7153\n",
      "Epoch 22 Batch 90 Loss 1.7361\n",
      "Epoch 22 Batch 100 Loss 1.7398\n",
      "Epoch 22 Batch 110 Loss 1.7133\n",
      "Epoch 22 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 36.00595498085022 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 1.7524\n",
      "Saved checkpoint for epoch 22: ./training_checkpoints_SSRN\\ckpt-23\n",
      "Epoch 23 Batch 0 Loss 1.7524\n",
      "Epoch 23 Batch 10 Loss 1.7366\n",
      "Epoch 23 Batch 20 Loss 1.7557\n",
      "Epoch 23 Batch 30 Loss 1.7413\n",
      "Epoch 23 Batch 40 Loss 1.7148\n",
      "Epoch 23 Batch 50 Loss 1.7324\n",
      "Epoch 23 Batch 60 Loss 1.7397\n",
      "Epoch 23 Batch 70 Loss 1.7469\n",
      "Epoch 23 Batch 80 Loss 1.7153\n",
      "Epoch 23 Batch 90 Loss 1.7361\n",
      "Epoch 23 Batch 100 Loss 1.7398\n",
      "Epoch 23 Batch 110 Loss 1.7133\n",
      "Epoch 23 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 35.040637493133545 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 1.7524\n",
      "Saved checkpoint for epoch 23: ./training_checkpoints_SSRN\\ckpt-24\n",
      "Epoch 24 Batch 0 Loss 1.7524\n",
      "Epoch 24 Batch 10 Loss 1.7366\n",
      "Epoch 24 Batch 20 Loss 1.7557\n",
      "Epoch 24 Batch 30 Loss 1.7413\n",
      "Epoch 24 Batch 40 Loss 1.7148\n",
      "Epoch 24 Batch 50 Loss 1.7324\n",
      "Epoch 24 Batch 60 Loss 1.7397\n",
      "Epoch 24 Batch 70 Loss 1.7469\n",
      "Epoch 24 Batch 80 Loss 1.7153\n",
      "Epoch 24 Batch 90 Loss 1.7361\n",
      "Epoch 24 Batch 100 Loss 1.7398\n",
      "Epoch 24 Batch 110 Loss 1.7133\n",
      "Epoch 24 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 35.21632480621338 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 1.7525\n",
      "Saved checkpoint for epoch 24: ./training_checkpoints_SSRN\\ckpt-25\n",
      "Epoch 25 Batch 0 Loss 1.7525\n",
      "Epoch 25 Batch 10 Loss 1.7366\n",
      "Epoch 25 Batch 20 Loss 1.7557\n",
      "Epoch 25 Batch 30 Loss 1.7413\n",
      "Epoch 25 Batch 40 Loss 1.7148\n",
      "Epoch 25 Batch 50 Loss 1.7324\n",
      "Epoch 25 Batch 60 Loss 1.7396\n",
      "Epoch 25 Batch 70 Loss 1.7470\n",
      "Epoch 25 Batch 80 Loss 1.7153\n",
      "Epoch 25 Batch 90 Loss 1.7361\n",
      "Epoch 25 Batch 100 Loss 1.7398\n",
      "Epoch 25 Batch 110 Loss 1.7133\n",
      "Epoch 25 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 34.7704975605011 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 1.7525\n",
      "Saved checkpoint for epoch 25: ./training_checkpoints_SSRN\\ckpt-26\n",
      "Epoch 26 Batch 0 Loss 1.7525\n",
      "Epoch 26 Batch 10 Loss 1.7366\n",
      "Epoch 26 Batch 20 Loss 1.7557\n",
      "Epoch 26 Batch 30 Loss 1.7413\n",
      "Epoch 26 Batch 40 Loss 1.7148\n",
      "Epoch 26 Batch 50 Loss 1.7323\n",
      "Epoch 26 Batch 60 Loss 1.7396\n",
      "Epoch 26 Batch 70 Loss 1.7470\n",
      "Epoch 26 Batch 80 Loss 1.7153\n",
      "Epoch 26 Batch 90 Loss 1.7361\n",
      "Epoch 26 Batch 100 Loss 1.7398\n",
      "Epoch 26 Batch 110 Loss 1.7133\n",
      "Epoch 26 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 34.24961018562317 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 1.7525\n",
      "Saved checkpoint for epoch 26: ./training_checkpoints_SSRN\\ckpt-27\n",
      "Epoch 27 Batch 0 Loss 1.7525\n",
      "Epoch 27 Batch 10 Loss 1.7366\n",
      "Epoch 27 Batch 20 Loss 1.7557\n",
      "Epoch 27 Batch 30 Loss 1.7413\n",
      "Epoch 27 Batch 40 Loss 1.7148\n",
      "Epoch 27 Batch 50 Loss 1.7323\n",
      "Epoch 27 Batch 60 Loss 1.7396\n",
      "Epoch 27 Batch 70 Loss 1.7470\n",
      "Epoch 27 Batch 80 Loss 1.7153\n",
      "Epoch 27 Batch 90 Loss 1.7361\n",
      "Epoch 27 Batch 100 Loss 1.7398\n",
      "Epoch 27 Batch 110 Loss 1.7133\n",
      "Epoch 27 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 37.023242473602295 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 1.7525\n",
      "Saved checkpoint for epoch 27: ./training_checkpoints_SSRN\\ckpt-28\n",
      "Epoch 28 Batch 0 Loss 1.7525\n",
      "Epoch 28 Batch 10 Loss 1.7366\n",
      "Epoch 28 Batch 20 Loss 1.7557\n",
      "Epoch 28 Batch 30 Loss 1.7413\n",
      "Epoch 28 Batch 40 Loss 1.7148\n",
      "Epoch 28 Batch 50 Loss 1.7323\n",
      "Epoch 28 Batch 60 Loss 1.7396\n",
      "Epoch 28 Batch 70 Loss 1.7470\n",
      "Epoch 28 Batch 80 Loss 1.7153\n",
      "Epoch 28 Batch 90 Loss 1.7361\n",
      "Epoch 28 Batch 100 Loss 1.7398\n",
      "Epoch 28 Batch 110 Loss 1.7133\n",
      "Epoch 28 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 37.77818989753723 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 1.7525\n",
      "Saved checkpoint for epoch 28: ./training_checkpoints_SSRN\\ckpt-29\n",
      "Epoch 29 Batch 0 Loss 1.7525\n",
      "Epoch 29 Batch 10 Loss 1.7366\n",
      "Epoch 29 Batch 20 Loss 1.7557\n",
      "Epoch 29 Batch 30 Loss 1.7413\n",
      "Epoch 29 Batch 40 Loss 1.7148\n",
      "Epoch 29 Batch 50 Loss 1.7323\n",
      "Epoch 29 Batch 60 Loss 1.7396\n",
      "Epoch 29 Batch 70 Loss 1.7470\n",
      "Epoch 29 Batch 80 Loss 1.7153\n",
      "Epoch 29 Batch 90 Loss 1.7361\n",
      "Epoch 29 Batch 100 Loss 1.7398\n",
      "Epoch 29 Batch 110 Loss 1.7133\n",
      "Epoch 29 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 37.55836248397827 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 1.7525\n",
      "Saved checkpoint for epoch 29: ./training_checkpoints_SSRN\\ckpt-30\n",
      "Epoch 30 Batch 0 Loss 1.7525\n",
      "Epoch 30 Batch 10 Loss 1.7366\n",
      "Epoch 30 Batch 20 Loss 1.7557\n",
      "Epoch 30 Batch 30 Loss 1.7413\n",
      "Epoch 30 Batch 40 Loss 1.7148\n",
      "Epoch 30 Batch 50 Loss 1.7323\n",
      "Epoch 30 Batch 60 Loss 1.7396\n",
      "Epoch 30 Batch 70 Loss 1.7470\n",
      "Epoch 30 Batch 80 Loss 1.7153\n",
      "Epoch 30 Batch 90 Loss 1.7362\n",
      "Epoch 30 Batch 100 Loss 1.7398\n",
      "Epoch 30 Batch 110 Loss 1.7133\n",
      "Epoch 30 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 35.21839475631714 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 1.7525\n",
      "Saved checkpoint for epoch 30: ./training_checkpoints_SSRN\\ckpt-31\n",
      "Epoch 31 Batch 0 Loss 1.7525\n",
      "Epoch 31 Batch 10 Loss 1.7366\n",
      "Epoch 31 Batch 20 Loss 1.7557\n",
      "Epoch 31 Batch 30 Loss 1.7413\n",
      "Epoch 31 Batch 40 Loss 1.7148\n",
      "Epoch 31 Batch 50 Loss 1.7323\n",
      "Epoch 31 Batch 60 Loss 1.7396\n",
      "Epoch 31 Batch 70 Loss 1.7470\n",
      "Epoch 31 Batch 80 Loss 1.7153\n",
      "Epoch 31 Batch 90 Loss 1.7362\n",
      "Epoch 31 Batch 100 Loss 1.7398\n",
      "Epoch 31 Batch 110 Loss 1.7133\n",
      "Epoch 31 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 36.83518052101135 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 1.7525\n",
      "Saved checkpoint for epoch 31: ./training_checkpoints_SSRN\\ckpt-32\n",
      "Epoch 32 Batch 0 Loss 1.7525\n",
      "Epoch 32 Batch 10 Loss 1.7366\n",
      "Epoch 32 Batch 20 Loss 1.7557\n",
      "Epoch 32 Batch 30 Loss 1.7413\n",
      "Epoch 32 Batch 40 Loss 1.7148\n",
      "Epoch 32 Batch 50 Loss 1.7323\n",
      "Epoch 32 Batch 60 Loss 1.7396\n",
      "Epoch 32 Batch 70 Loss 1.7471\n",
      "Epoch 32 Batch 80 Loss 1.7152\n",
      "Epoch 32 Batch 90 Loss 1.7362\n",
      "Epoch 32 Batch 100 Loss 1.7398\n",
      "Epoch 32 Batch 110 Loss 1.7133\n",
      "Epoch 32 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 34.466557264328 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 1.7525\n",
      "Saved checkpoint for epoch 32: ./training_checkpoints_SSRN\\ckpt-33\n",
      "Epoch 33 Batch 0 Loss 1.7525\n",
      "Epoch 33 Batch 10 Loss 1.7366\n",
      "Epoch 33 Batch 20 Loss 1.7557\n",
      "Epoch 33 Batch 30 Loss 1.7413\n",
      "Epoch 33 Batch 40 Loss 1.7148\n",
      "Epoch 33 Batch 50 Loss 1.7323\n",
      "Epoch 33 Batch 60 Loss 1.7396\n",
      "Epoch 33 Batch 70 Loss 1.7471\n",
      "Epoch 33 Batch 80 Loss 1.7152\n",
      "Epoch 33 Batch 90 Loss 1.7362\n",
      "Epoch 33 Batch 100 Loss 1.7398\n",
      "Epoch 33 Batch 110 Loss 1.7133\n",
      "Epoch 33 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 34.556901931762695 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 1.7526\n",
      "Saved checkpoint for epoch 33: ./training_checkpoints_SSRN\\ckpt-34\n",
      "Epoch 34 Batch 0 Loss 1.7526\n",
      "Epoch 34 Batch 10 Loss 1.7366\n",
      "Epoch 34 Batch 20 Loss 1.7557\n",
      "Epoch 34 Batch 30 Loss 1.7413\n",
      "Epoch 34 Batch 40 Loss 1.7148\n",
      "Epoch 34 Batch 50 Loss 1.7323\n",
      "Epoch 34 Batch 60 Loss 1.7396\n",
      "Epoch 34 Batch 70 Loss 1.7471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 80 Loss 1.7152\n",
      "Epoch 34 Batch 90 Loss 1.7362\n",
      "Epoch 34 Batch 100 Loss 1.7398\n",
      "Epoch 34 Batch 110 Loss 1.7133\n",
      "Epoch 34 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 34.259143114089966 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 1.7526\n",
      "Saved checkpoint for epoch 34: ./training_checkpoints_SSRN\\ckpt-35\n",
      "Epoch 35 Batch 0 Loss 1.7526\n",
      "Epoch 35 Batch 10 Loss 1.7366\n",
      "Epoch 35 Batch 20 Loss 1.7557\n",
      "Epoch 35 Batch 30 Loss 1.7413\n",
      "Epoch 35 Batch 40 Loss 1.7148\n",
      "Epoch 35 Batch 50 Loss 1.7323\n",
      "Epoch 35 Batch 60 Loss 1.7396\n",
      "Epoch 35 Batch 70 Loss 1.7471\n",
      "Epoch 35 Batch 80 Loss 1.7152\n",
      "Epoch 35 Batch 90 Loss 1.7362\n",
      "Epoch 35 Batch 100 Loss 1.7398\n",
      "Epoch 35 Batch 110 Loss 1.7133\n",
      "Epoch 35 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 35.02066612243652 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 1.7526\n",
      "Saved checkpoint for epoch 35: ./training_checkpoints_SSRN\\ckpt-36\n",
      "Epoch 36 Batch 0 Loss 1.7526\n",
      "Epoch 36 Batch 10 Loss 1.7366\n",
      "Epoch 36 Batch 20 Loss 1.7557\n",
      "Epoch 36 Batch 30 Loss 1.7413\n",
      "Epoch 36 Batch 40 Loss 1.7148\n",
      "Epoch 36 Batch 50 Loss 1.7323\n",
      "Epoch 36 Batch 60 Loss 1.7396\n",
      "Epoch 36 Batch 70 Loss 1.7471\n",
      "Epoch 36 Batch 80 Loss 1.7152\n",
      "Epoch 36 Batch 90 Loss 1.7362\n",
      "Epoch 36 Batch 100 Loss 1.7398\n",
      "Epoch 36 Batch 110 Loss 1.7133\n",
      "Epoch 36 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 35.307294607162476 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 1.7526\n",
      "Saved checkpoint for epoch 36: ./training_checkpoints_SSRN\\ckpt-37\n",
      "Epoch 37 Batch 0 Loss 1.7526\n",
      "Epoch 37 Batch 10 Loss 1.7366\n",
      "Epoch 37 Batch 20 Loss 1.7557\n",
      "Epoch 37 Batch 30 Loss 1.7413\n",
      "Epoch 37 Batch 40 Loss 1.7148\n",
      "Epoch 37 Batch 50 Loss 1.7323\n",
      "Epoch 37 Batch 60 Loss 1.7396\n",
      "Epoch 37 Batch 70 Loss 1.7471\n",
      "Epoch 37 Batch 80 Loss 1.7152\n",
      "Epoch 37 Batch 90 Loss 1.7362\n",
      "Epoch 37 Batch 100 Loss 1.7398\n",
      "Epoch 37 Batch 110 Loss 1.7133\n",
      "Epoch 37 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 35.35364818572998 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 1.7526\n",
      "Saved checkpoint for epoch 37: ./training_checkpoints_SSRN\\ckpt-38\n",
      "Epoch 38 Batch 0 Loss 1.7526\n",
      "Epoch 38 Batch 10 Loss 1.7366\n",
      "Epoch 38 Batch 20 Loss 1.7557\n",
      "Epoch 38 Batch 30 Loss 1.7413\n",
      "Epoch 38 Batch 40 Loss 1.7148\n",
      "Epoch 38 Batch 50 Loss 1.7323\n",
      "Epoch 38 Batch 60 Loss 1.7396\n",
      "Epoch 38 Batch 70 Loss 1.7471\n",
      "Epoch 38 Batch 80 Loss 1.7152\n",
      "Epoch 38 Batch 90 Loss 1.7362\n",
      "Epoch 38 Batch 100 Loss 1.7398\n",
      "Epoch 38 Batch 110 Loss 1.7133\n",
      "Epoch 38 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 35.02777433395386 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 1.7526\n",
      "Saved checkpoint for epoch 38: ./training_checkpoints_SSRN\\ckpt-39\n",
      "Epoch 39 Batch 0 Loss 1.7526\n",
      "Epoch 39 Batch 10 Loss 1.7366\n",
      "Epoch 39 Batch 20 Loss 1.7557\n",
      "Epoch 39 Batch 30 Loss 1.7413\n",
      "Epoch 39 Batch 40 Loss 1.7148\n",
      "Epoch 39 Batch 50 Loss 1.7323\n",
      "Epoch 39 Batch 60 Loss 1.7396\n",
      "Epoch 39 Batch 70 Loss 1.7471\n",
      "Epoch 39 Batch 80 Loss 1.7152\n",
      "Epoch 39 Batch 90 Loss 1.7362\n",
      "Epoch 39 Batch 100 Loss 1.7398\n",
      "Epoch 39 Batch 110 Loss 1.7133\n",
      "Epoch 39 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 34.63206648826599 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 1.7526\n",
      "Saved checkpoint for epoch 39: ./training_checkpoints_SSRN\\ckpt-40\n",
      "Epoch 40 Batch 0 Loss 1.7526\n",
      "Epoch 40 Batch 10 Loss 1.7366\n",
      "Epoch 40 Batch 20 Loss 1.7557\n",
      "Epoch 40 Batch 30 Loss 1.7413\n",
      "Epoch 40 Batch 40 Loss 1.7148\n",
      "Epoch 40 Batch 50 Loss 1.7323\n",
      "Epoch 40 Batch 60 Loss 1.7396\n",
      "Epoch 40 Batch 70 Loss 1.7471\n",
      "Epoch 40 Batch 80 Loss 1.7152\n",
      "Epoch 40 Batch 90 Loss 1.7362\n",
      "Epoch 40 Batch 100 Loss 1.7398\n",
      "Epoch 40 Batch 110 Loss 1.7133\n",
      "Epoch 40 Batch 120 Loss 1.7389\n",
      "Time taken for 1 epoch 37.747297286987305 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (mels,mags)) in enumerate(pad_batch.take(steps_per_epoch)):\n",
    "        batch_loss = train_step_SSRN(mels,mags)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        \n",
    "        \n",
    "        if batch % 10 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                           batch,\n",
    "                                                           batch_loss.numpy()))\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "        if int(batch) % 500 == 0:\n",
    "            save_path = manager.save()\n",
    "            print(\"Saved checkpoint for epoch {}: {}\".format(int(epoch), save_path))\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                           batch,\n",
    "                                                           batch_loss.numpy()))\n",
    "\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
